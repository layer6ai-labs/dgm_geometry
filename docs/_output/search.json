[
  {
    "objectID": "sections/ood/ood_guide.html",
    "href": "sections/ood/ood_guide.html",
    "title": "A Hands-on Guide",
    "section": "",
    "text": "This is a Jupyter notebook that will guide you through how to use our codebase to perform OOD detection. For simplicity, we consider OOD detection between the two greuscale image datasets: FMNIST and MNIST, where once we train a model on FMNIST and try to predict MNIST points as out-of-distribution, and another time train a model on MNIST and try to predict FMNIST as out-of-distribution. Once you have gone through these steps, you can easily extend it to other dataset pairs, or even introduce your own datasets to perform OOD detection.\nBefore we start, it is recommended to run the following script that downloads all the necessary resources that we will use in this notebool such as model checkpoints that are already trained on MNIST and FMNIST datasets, alongside some report files that we have already run on these models.\nThe approach we follow here is that we will use some of the python scripts in the repository that output useful logs onto mlflow, such as the likelihood of different datapoints on different models. Then, we will use these logs and artifacts to visualize the results here. Make sure you run your scripts on the root of the repository and that you have followed the setup instructions to have mlflow running. Before we proceed, please run the following cell to import the necessary libraries and functions.\nCode\n%load_ext autoreload\n%autoreload 2\nimport torch\nfrom notebook_setup import device\ntorch.manual_seed(0)\nimport warnings\n# Suppress specific warnings\nwarnings.filterwarnings(\"ignore\", message=\".*IProgress not found.*\")",
    "crumbs": [
      "Home",
      "Out-of-distribution detection",
      "A Hands-on Guide"
    ]
  },
  {
    "objectID": "sections/ood/ood_guide.html#running-checkpoints",
    "href": "sections/ood/ood_guide.html#running-checkpoints",
    "title": "A Hands-on Guide",
    "section": "1 Running checkpoints",
    "text": "1 Running checkpoints\nHere, we will work with diffusion and flow models that have been trained on MNIST and FMNIST datasets. Run the following bash commands to get 4 different mlflow logs for each model. If you have setup the repository correctly, this will produce an artifact file that contains a &lt;artifact_dir&gt;/samples_grid/xxx.png that contains relevant samples produces by these models.\n# diffusion trained on fmnist\npython scripts/train.py dataset=fmnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_fmnist\n# diffusion trained on mnist\npython scripts/train.py dataset=mnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_mnist\n# flow trained on fmnist\npython scripts/train.py dataset=fmnist +experiment=train_flow_greyscale +checkpoint=flow_fmnist\n# flow trained on mnist\npython scripts/train.py dataset=mnist +experiment=train_flow_greyscale +checkpoint=flow_mnist",
    "crumbs": [
      "Home",
      "Out-of-distribution detection",
      "A Hands-on Guide"
    ]
  },
  {
    "objectID": "sections/ood/ood_guide.html#the-likelihood-paradox",
    "href": "sections/ood/ood_guide.html#the-likelihood-paradox",
    "title": "A Hands-on Guide",
    "section": "2 The likelihood paradox",
    "text": "2 The likelihood paradox\nWe first reproduce the likelihood OOD paradox, whereby the likelihood of OOD data, even though unseen during training, will be larger than that of in-distribution data. To do so, we can use the following commands to reproduce this for both flows and diffusions.\n# fmnist vs. mnist on flows\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_flow_greyscale +checkpoint=flow_fmnist +ood=flow_likelihood_paradox\n# mnist vs. fmnist on flows\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_flow_greyscale +checkpoint=flow_mnist +ood=flow_likelihood_paradox\n# fmnist vs. mnist on diffusions\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_fmnist +ood=diffusion_likelihood_paradox\n# mnist vs. fmnist on diffusions\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_mnist +ood=diffusion_likelihood_paradox\nYou may also add the extra options ood_subsample_size=&lt;x&gt; and ood_batch_size=&lt;x&gt; to control the number of samples used for OOD detection. The default values here are 4096 and 128, respectively. This is because the OOD detection for diffusions in particular can be computationally expensive, and we might need to subsample the OOD data to make it feasible.\nNote that we use the train.py script rather than a dedicated script for OOD detection. This is because the OOD detection is a simple extension of the training script, even when a checkpoint is unavailable, you can run the same script and it will train a model on the in-distribution data for the purpose of OOD detection. However, the most important reason of having it as an extension of train.py is that OOD detection using likelihoods, or as we will see, with LID, can be seen as monitoring different metrics of datapoints during training. Therefore, we implement it as a callback that can be used during training. We can then compose multiple callbacks to monitor different metrics, such as the likelihood of the data, the LID of the data, etc.\nBefore moving on, let us visualize the likelihoods that we obtain. Every script will create an mlflow experiment with an appropriate mlflow artifacts directory. The artifacts should lie in outputs/mlruns/??/??/artifacts/ and you can visualize them using the mlflow console as well. When moving to the logs of each of these runs, you will notice the following directories:\n\nsamples_grid/xxx.png: contains samples produced by the generative model and serves as a sanity check.\nlikelihood_in_distr_train/: This contains the monitoring results of the in-distribution data from the training set.\nlikelihood_in_distr_test/: This contains the monitoring results of the in-distribution data from the test set.\nlikelihood_ood/: This contains the monitoring results of the OOD data.\nlikelihood_generated/: This contains the monitoring results of the generated data.\n\nEach of these directories contains a metrics=xxx.csv file with a column labelled as LikelihoodMetric that contains the likelihoods of the data. We can use these likelihoods to visualize the likelihood paradox. Moreover, there is a samples/idx.png for idx ranging over the number of samples that we have used for monitoring. We can use these samples to visualize and have access to the samples that have been used for monitoring.\nNext, we store the artifact directory in our .env folder:\ndotenv set OOD_LIKELIHOOD_PARADOX_FLOW_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_FLOW_MNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_DIFFUSION_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_DIFFUSION_MNIST &lt;corresponding_artifact_dir&gt;\nNote that if you have used our download_resources.py script, the results should be stored in the .env file already with some artifact directories that we have already used. Therefore, you can skip the step of generating these artifacts if the script takes too long to run on your machine. In fact, this pattern will be repeated for the rest of the notebook, where we introduce the set of commands to generate artifacts, and we also store our own runs already in the .env file if you have used the download_resources.py script.\nNow, use the following cell to visualize the content in these tables. It will visualize 4 different plots showing the histogram of likelihoods for OOD samples, in-distribution (test and train split), and also, the generated samples (in gold). We see the peculiar behaviour on the generated samples’ likelihoods as well which is always smaller than the in-distribution samples.\n\n\nCode\n%autoreload 2\nimport dotenv\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom visualization.pretty import ColorTheme\n# load the environment variables\ndotenv.load_dotenv(override=True)\nimport os\n\ndef visualize_likelihood_ood(ax, artifact_dir: str, title: str, bins: int = 100):\n    # find the directory {artifact_dir}/likelihood_generated/metrics=xxx.csv`\n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_generated\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_generated = pd.read_csv(metrics_dir)['LikelihoodMetric']\n\n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_ood\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_ood = pd.read_csv(metrics_dir)['LikelihoodMetric']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_in_distr_train\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_train = pd.read_csv(os.path.join(artifact_dir, metrics_dir))['LikelihoodMetric']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_in_distr_test\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_test = pd.read_csv(os.path.join(artifact_dir, metrics_dir))['LikelihoodMetric']\n\n    # plot an overlapping histogram\n    ax.hist(likelihood_generated, bins=bins, alpha=0.5, label=\"Generated\", density=True, color=ColorTheme.GOLD.value)\n    ax.hist(likelihood_ood, bins=bins, alpha=0.5, label=\"OOD\", density=True, color=ColorTheme.RED_FIRST.value)\n    ax.hist(likelihood_in_distr_train, bins=bins, alpha=0.5, label=\"In-distribution train\", density=True, color=ColorTheme.BLUE_FIRST.value)\n    ax.hist(likelihood_in_distr_test, bins=bins, alpha=0.5, label=\"In-distribution test\", density=True, color=ColorTheme.BLUE_SECOND.value)\n    ax.set_title(title)\n    ax.legend()\n\nfig, axs = plt.subplots(2, 2, figsize=(8, 6))\n\nvisualize_likelihood_ood(\n    ax=axs[0, 0],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_FLOW_FMNIST\"),\n    title=\"Paradoxical Flow Fashion FMNIST vs. MNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[0, 1],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_FLOW_MNIST\"),\n    title=\"Non-Paradoxical Flow MNIST vs. FMNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[1, 0],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_DIFFUSION_FMNIST\"),\n    title=\"Paradoxical Diffusion FMNIST vs. MNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[1, 1],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_DIFFUSION_MNIST\"),\n    title=\"Non-Paradoxical Diffusion MNIST vs. FMNIST\",\n    bins=66,\n)\n# Adjust layout and spacing\nplt.tight_layout(pad=1.0)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: The likelihood OOD paradox visualized in both FMNIST- and MNIST-trained models for normalizing flows and diffusion models.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection",
      "A Hands-on Guide"
    ]
  },
  {
    "objectID": "sections/ood/ood_guide.html#monitoring-lid-on-both-in--and-out-of-distribution-data",
    "href": "sections/ood/ood_guide.html#monitoring-lid-on-both-in--and-out-of-distribution-data",
    "title": "A Hands-on Guide",
    "section": "3 Monitoring LID on both In- and Out-of-distribution Data",
    "text": "3 Monitoring LID on both In- and Out-of-distribution Data\nIn the paper “A Geometric Explanation of the Likelihood OOD Detection Paradox” (Kamkari, Ross, Cresswell, et al. 2024), the hyperparameters related to the LID estimation are calibrated using the training data an an external model-free LID estimator. Some prior and follow-up work such as LIDL (Tempczyk et al. 2022) and FLIPD (Kamkari, Ross, Hosseinzadeh, et al. 2024) have shown that model-free estimators are not reliable for high-dimensional image data. Thus, instead of calibrating the hyperparamter \\tau using a model-free estimator, we pick a subset of in- and out-of-distribution datapoints and visualize an LID curve: a curve for each datapoint indicating their LID estimate for all different values of \\tau. Through this, we illustrate how the LID of OOD datapoints when they have a higher likelihood estimate (are paradoxical) is generally lower than the LID of in-distribution datapoints, without the need for any calibration.\nSimilar to before, we use an appropriate callback to do so and this will log certain artifacts in mlflow:\n# fmnist vs. mnist on flows\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_flow_greyscale +checkpoint=flow_fmnist +ood=flow_lid_curve\n# mnist vs. fmnist on flows\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_flow_greyscale +checkpoint=flow_mnist +ood=flow_lid_curve\n# fmnist vs. mnist on diffusions\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_fmnist +ood=diffusion_lid_curve\n# mnist vs. fmnist on diffusions\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_mnist +ood=diffusion_lid_curve\nAgain, each run will create an artifact directory and you can store them in the .env file using the following commands:\ndotenv set OOD_LID_CURVE_FLOW_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LID_CURVE_FLOW_MNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LID_CURVE_DIFFUSION_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LID_CURVE_DIFFUSION_MNIST &lt;corresponding_artifact_dir&gt;\nNow, by looking at the artifact directories, we will notice that we will have the same structure as before:\n\nlid_curve_generated: This contains the LID curve of the generated data.\nlid_curve_in_distr_train: This contains the LID curve of the in-distribution data from the training set.\nlid_curve_in_distr_test: This contains the LID curve of the in-distribution data from the test set.\nlid_curve_ood: This contains the LID curve of the OOD data.\n\nEach of these files will already contain the LID curve png file in trends/trend_epoch=xxx.png. We care about the raw data here, which is inside a csv file trends/trend_epoch=xxx.csv. Here, we will use the csv files of lid_curve_in_distr_test versus the lid_curve_ood and the following code will visualize the LID curves for the in-distribution and OOD data.\n\n\nCode\n%autoreload 2\nimport dotenv\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport re\nfrom visualization.pretty import ColorTheme\nfrom visualization.trend import plot_trends\n# load the environment variables\ndotenv.load_dotenv(override=True)\nimport os\n\ndef visualize_lid_ood_curve(ax, artifact_dir: str, title: str, alpha=0.01, x_label=\"Sweeping argument\", y_label=\"LID\"):\n    # find the directory {artifact_dir}/likelihood_generated/metrics=xxx.csv`\n    lid_curve_dir = os.path.join(artifact_dir, \"lid_curve_in_distr_test\", \"trends\")\n    trend_files = [f for f in os.listdir(lid_curve_dir) if re.match(r'trend_epoch=\\d+\\.csv', f)][0]\n    trend_in = pd.read_csv(os.path.join(lid_curve_dir, trend_files), index_col=0).values\n\n    lid_curve_dir = os.path.join(artifact_dir, \"lid_curve_ood\", \"trends\")\n    trend_files = [f for f in os.listdir(lid_curve_dir) if re.match(r'trend_epoch=\\d+\\.csv', f)][0]\n    trend_ood = pd.read_csv(os.path.join(lid_curve_dir, trend_files), index_col=0).values\n\n    sweeping_args_file = [f for f in os.listdir(lid_curve_dir) if f.startswith(\"sweeping_range\")][0]\n    sweeping_args_df = pd.read_csv(os.path.join(lid_curve_dir, sweeping_args_file), index_col=0)\n    \n    sweeping_arg = sweeping_args_df.columns[0]\n    sweeping_values = sweeping_args_df[sweeping_arg].values\n    for i in range(trend_in.shape[0]):\n        ax.plot(sweeping_values, trend_in[i], color=ColorTheme.BLUE_FIRST.value, alpha=alpha)\n    ax.plot([], [], color=ColorTheme.BLUE_FIRST.value, label=\"In-distribution\")\n    for i in range(trend_ood.shape[0]):\n        ax.plot(sweeping_values, trend_ood[i], color=ColorTheme.RED_FIRST.value, alpha=alpha)\n    ax.plot([], [], color=ColorTheme.RED_FIRST.value, label=\"OOD\")\n    ax.set_title(title)\n    ax.legend()\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(y_label)\n\n\nfig, axs = plt.subplots(2, 2, figsize=(8, 6))\n\nvisualize_lid_ood_curve(\n    ax=axs[0, 0],\n    artifact_dir=os.getenv(\"OOD_LID_CURVE_FLOW_FMNIST\"),\n    title=\"Paradoxical Flow FMNIST vs. MNIST\",\n    alpha=0.08,\n    x_label=\"$\\\\log \\\\tau$\",\n)\nvisualize_lid_ood_curve(\n    ax=axs[0, 1],\n    artifact_dir=os.getenv(\"OOD_LID_CURVE_FLOW_MNIST\"),\n    title=\"Non-Paradoxical Flow MNIST vs. FMNIST\",\n    alpha=0.08,\n    x_label=\"$\\\\log \\\\tau$\",\n)\nvisualize_lid_ood_curve(\n    ax=axs[1, 0],\n    artifact_dir=os.getenv(\"OOD_LID_CURVE_DIFFUSION_FMNIST\"),\n    title=\"Paradoxical Diffusion FMNIST vs. MNIST\",\n    alpha=0.08,\n    x_label=\"$\\\\log \\\\tau$\",\n)\nvisualize_lid_ood_curve(\n    ax=axs[1, 1],\n    artifact_dir=os.getenv(\"OOD_LID_CURVE_DIFFUSION_MNIST\"),\n    title=\"Non-Paradoxical Diffusion MNIST vs. FMNIST\",\n    alpha=0.08,\n    x_label=\"$\\\\log \\\\tau$\",\n)\n# Adjust layout and spacing\nplt.tight_layout(pad=1.0)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nFigure 2: Visualizing the LID of in- and out-of-distribution data for normalizing flows and diffusion models as a curve over a sweeping argument, which in this case is the log thresholding parameter \\tau.\n\n\n\n\n\nAs expected, when \\tau \\to 0, meaning that \\log \\tau is very negative, then the LID is estimated as the ambient dimension, and when it is large, it is estimated as zero. Therefore, we have to judiciously pick a \\tau value that produces somewhat reasonable estimates. By looking at the curves, it is clear that at certain values of \\tau the LID estimate plateaus or shows interesting behaviour. Regardless, looking at the above plots, it is clear that in the paradoxical scenarios (the left half) the LID of in-distribution data is larger than the out-of-distribution counterpart. In fact, for a very small \\tau, even on the upper-right, we see that the LID of in-distribution data is larger than the out-of-distribution data which complies with the scatterplot results in (Kamkari, Ross, Cresswell, et al. 2024). Following the paper, let us pick \\tau using a calibration procedure that utilizes an external model-free LID estimator. To get access to the calibration LID values, you can run our model-free LID estimator scripts, which under the hood, uses the scikit-dim LPCA estimator. Note that if you run the same script without the alphaFO calibration, it will produce unreasonably small values, such as 8 for FMNIST. This is inline with (Kamkari, Ross, Hosseinzadeh, et al. 2024) where shows that, without tuning, model-free LID estimators are not reliable for high-dimensional image data.\npython scripts/model_free_lid.py dataset=fmnist lid_method=lpca +lid_method.estimator.alphaFO=0.001 +experiment=lid_greyscale # will produce ~ 222.48\npython scripts/model_free_lid.py dataset=mnist lid_method=lpca +lid_method.estimator.alphaFO=0.001 +experiment=lid_greyscale # will produce ~ 251.62\nNote that while these estimates are not reasonable on their own, they give us a baseline to calibrate \\tau with. The following piece of code does that logic and visualizes the \\tau values that produce the average LID that aligns most with these estimates. By looking at the dashed gold lines, it is easy to see that in the paradoxical scenarios, the \\tau value will produce LID estimates on the image above that can separate the in-distribution and out-of-distribution data.\n\n\nCode\n%autoreload 2\nimport dotenv\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport re\nfrom visualization.pretty import ColorTheme\nfrom visualization.trend import plot_trends\n# load the environment variables\ndotenv.load_dotenv(override=True)\nimport os\n\ndef visualize_calibration(\n    ax, \n    artifact_dir: str, \n    title: str, \n    calibration_average_lid: float, \n    alpha=0.01, \n    x_label=\"Sweeping argument\", \n    y_label=\"LID\"\n):\n    # find the directory {artifact_dir}/likelihood_generated/metrics=xxx.csv`\n    lid_curve_dir = os.path.join(artifact_dir, \"lid_curve_in_distr_train\", \"trends\")\n    trend_files = [f for f in os.listdir(lid_curve_dir) if re.match(r'trend_epoch=\\d+\\.csv', f)][0]\n    trend_in = pd.read_csv(os.path.join(lid_curve_dir, trend_files), index_col=0).values\n\n    sweeping_args_file = [f for f in os.listdir(lid_curve_dir) if f.startswith(\"sweeping_range\")][0]\n    sweeping_args_df = pd.read_csv(os.path.join(lid_curve_dir, sweeping_args_file), index_col=0)\n    \n    sweeping_arg = sweeping_args_df.columns[0]\n    sweeping_values = sweeping_args_df[sweeping_arg].values\n\n    best_log_tau = None\n    best_avg = None\n    for i, val in enumerate(sweeping_values):\n        col = trend_in[:, i]\n        avg = trend_in[:, i].mean()\n        if best_log_tau is None or abs(avg - calibration_average_lid) &lt; abs(best_avg - calibration_average_lid):\n            best_log_tau = val\n            best_avg = avg\n        \n    for i in range(trend_in.shape[0]):\n        ax.plot(sweeping_values, trend_in[i], color=ColorTheme.BLUE_FIRST.value, alpha=alpha)\n    ax.plot([], [], color=ColorTheme.BLUE_SECOND.value, label=\"Training Data\")\n    ax.axvline(x=best_log_tau, color=ColorTheme.PIRATE_GOLD.value, label=\"Calibrated $\\\\log \\\\tau$\", linestyle=\"--\")\n    ax.axhline(y=calibration_average_lid, color=ColorTheme.RED_FIRST.value, label=\"Calibration LID\", linestyle=\"--\")\n    ax.set_title(title)\n    ax.legend()\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(y_label)\n\n\nfig, axs = plt.subplots(2, 2, figsize=(8, 6))\n\nvisualize_calibration(\n    ax=axs[0, 0],\n    artifact_dir=os.getenv(\"OOD_LID_CURVE_FLOW_FMNIST\"),\n    calibration_average_lid=222.48,\n    title=\"Calibrating LID for Flow FMNIST\",\n    alpha=0.08,\n    x_label=\"$\\\\log \\\\tau$\",\n)\nvisualize_calibration(\n    ax=axs[0, 1],\n    artifact_dir=os.getenv(\"OOD_LID_CURVE_FLOW_MNIST\"),\n    calibration_average_lid=251.62,\n    title=\"Calibrating LID for Flow MNIST\",\n    alpha=0.08,\n    x_label=\"$\\\\log \\\\tau$\",\n)\nvisualize_calibration(\n    ax=axs[1, 0],\n    artifact_dir=os.getenv(\"OOD_LID_CURVE_DIFFUSION_FMNIST\"),\n    calibration_average_lid=222.48,\n    title=\"Calibrating LID for Diffusion FMNIST\",\n    alpha=0.08,\n    x_label=\"$\\\\log \\\\tau$\",\n)\nvisualize_calibration(\n    ax=axs[1, 1],\n    artifact_dir=os.getenv(\"OOD_LID_CURVE_DIFFUSION_MNIST\"),\n    calibration_average_lid=251.62,\n    title=\"Calibrating LID for Diffusion MNIST\",\n    alpha=0.08,\n    x_label=\"$\\\\log \\\\tau$\",\n)\nplt.tight_layout(pad=1.0)\nplt.show()\n\n\n\n\n\n\n\n\n\nFigure 3: Visualizing the calibration of \\tau using training data.\n\n\n\n\n\nWe note that the calibration step seems somewhat arbitrary! Indeed, as long as \\tau is set such that the in- and out-of-distribution LID estimates are well-separated, it should be good enough for OOD detection. Therefore, while we use this calibration for generating the results in our paper, here we set \\tau to a fixed value for simplicity. In the following we fix \\tau such that \\log \\tau = -3. The reason why we fix it to that value is that by looking at the training data, it seems to be a reasonable \\tau value where “interesting” things happen in the LID curve for training data.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection",
      "A Hands-on Guide"
    ]
  },
  {
    "objectID": "sections/ood/ood_guide.html#scatterplot-of-lid-and-likelihood",
    "href": "sections/ood/ood_guide.html#scatterplot-of-lid-and-likelihood",
    "title": "A Hands-on Guide",
    "section": "4 Scatterplot of LID and Likelihood",
    "text": "4 Scatterplot of LID and Likelihood\nBy fixing the threshold value, we can now run the following command to jointly logging the likelihood and LID values of the in-distribution and OOD data.\n# fmnist vs. mnist on flows\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_flow_greyscale +checkpoint=flow_fmnist +ood=flow_lid_likelihood +lid_metric.singular_value_threshold=-3\n# mnist vs. fmnist on flows\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_flow_greyscale +checkpoint=flow_mnist +ood=flow_lid_likelihood +lid_metric.singular_value_threshold=-3\n# fmnist vs. mnist on diffusions\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_fmnist +ood=diffusion_lid_likelihood +lid_metric.singular_value_threshold=-3\n# mnist vs. fmnist on diffusions\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_mnist +ood=diffusion_lid_likelihood +lid_metric.singular_value_threshold=-3\nAgain, each run will create an artifact directory and you can store them in the .env file using the following commands:\ndotenv set OOD_LID_LIKELIHOOD_FLOW_FMNIST_1 &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LID_LIKELIHOOD_FLOW_MNIST_1 &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LID_LIKELIHOOD_DIFFUSION_FMNIST_1 &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LID_LIKELIHOOD_DIFFUSION_MNIST_1 &lt;corresponding_artifact_dir&gt;\n\n\nCode\n%autoreload 2\nimport dotenv\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom visualization.pretty import ColorTheme\n# load the environment variables\ndotenv.load_dotenv(override=True)\nimport os\n\ndef visualize_scatterplot(\n    ax, \n    artifact_dir: str, \n    title: str, \n    alpha=0.01, \n):\n    # find the directory {artifact_dir}/likelihood_generated/metrics=xxx.csv`\n    likelihood_dir = os.path.join(artifact_dir, \"lid_likelihood_generated\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_generated = pd.read_csv(metrics_dir)['likelihood']\n    lid_generated = pd.read_csv(metrics_dir)['JacobianThresholdLID']\n\n    likelihood_dir = os.path.join(artifact_dir, \"lid_likelihood_ood\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_ood = pd.read_csv(metrics_dir)['likelihood']\n    lid_ood = pd.read_csv(metrics_dir)['JacobianThresholdLID']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"lid_likelihood_in_distr_train\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_train = pd.read_csv(metrics_dir)['likelihood']\n    lid_in_distr_train = pd.read_csv(metrics_dir)['JacobianThresholdLID']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"lid_likelihood_in_distr_test\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_test = pd.read_csv(metrics_dir)['likelihood']\n    lid_in_distr_test = pd.read_csv(metrics_dir)['JacobianThresholdLID']\n\n    # plot an overlapping histogram\n    ax.scatter(likelihood_generated, lid_generated, alpha=alpha, label=\"Generated\", color=ColorTheme.GOLD.value)\n    ax.scatter(likelihood_ood, lid_ood, alpha=alpha, label=\"OOD\", color=ColorTheme.RED_FIRST.value)\n    ax.scatter(likelihood_in_distr_train, lid_in_distr_train, alpha=alpha, label=\"In-distribution train\", color=ColorTheme.BLUE_FIRST.value)\n    ax.scatter(likelihood_in_distr_test, lid_in_distr_test, alpha=alpha, label=\"In-distribution test\", color=ColorTheme.BLUE_SECOND.value)\n    ax.set_xlabel(\"Log Likelihood\")\n    ax.set_ylabel(\"LID(.;$\\\\tau$)\")\n    ax.set_title(title)\n    ax.legend()\n    return {\n        \"generated\": (likelihood_generated, lid_generated),\n        \"ood\": (likelihood_ood, lid_ood),\n        \"in_distr_train\": (likelihood_in_distr_train, lid_in_distr_train),\n        \"in_distr_test\": (likelihood_in_distr_test, lid_in_distr_test),\n    }\n\n\nfig, axs = plt.subplots(2, 2, figsize=(8, 6))\n\nlid_likelihood_flow_fmnist_1 = visualize_scatterplot(\n    ax=axs[0, 0],\n    artifact_dir=os.getenv(\"OOD_LID_LIKELIHOOD_FLOW_FMNIST_1\"),\n    title=\"Scatterplot on Flow FMNIST ($\\\\log \\\\tau=-3$)\",\n    alpha=0.6,\n)\n\nlid_likelihood_flow_mnist_1 = visualize_scatterplot(\n    ax=axs[0, 1],\n    artifact_dir=os.getenv(\"OOD_LID_LIKELIHOOD_FLOW_MNIST_1\"),\n    title=\"Scatterplot on Flow MNIST ($\\\\log \\\\tau=-3$)\",\n    alpha=0.6,\n)\n\nlid_likelihood_diffusion_fmnist_1 = visualize_scatterplot(\n    ax=axs[1, 0],\n    artifact_dir=os.getenv(\"OOD_LID_LIKELIHOOD_DIFFUSION_FMNIST_1\"),\n    title=\"Scatterplot on Diffusion FMNIST ($\\\\log \\\\tau=-3$)\",\n    alpha=0.6,\n)\nlid_likelihood_diffusion_mnist_1 = visualize_scatterplot(\n    ax=axs[1, 1],\n    artifact_dir=os.getenv(\"OOD_LID_LIKELIHOOD_DIFFUSION_MNIST_1\"),\n    title=\"Scatterplot on Diffusion FMNIST ($\\\\log \\\\tau=-3$)\",\n    alpha=0.6,\n)\nplt.tight_layout(pad=1.0)\nplt.show()\n\n\n\n\n\n\n\n\n\nFigure 4: Visualizing scatterplot of LID and likelihood for in- and out-of-distribution data for normalizing flows and diffusion models.\n\n\n\n\n\nWe will also try out another \\tau value below to show that LID is not always inversely related to likelihood.\n# fmnist vs. mnist on flows\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_flow_greyscale +checkpoint=flow_fmnist +ood=flow_lid_likelihood +lid_metric.singular_value_threshold=-5\n# mnist vs. fmnist on flows\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_flow_greyscale +checkpoint=flow_mnist +ood=flow_lid_likelihood +lid_metric.singular_value_threshold=-5\n# save the artifact directories\ndotenv set OOD_LID_LIKELIHOOD_FLOW_FMNIST_2 &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LID_LIKELIHOOD_FLOW_MNIST_2 &lt;corresponding_artifact_dir&gt;\n\n\nCode\nfig, axs = plt.subplots(1, 2, figsize=(8, 3))\n\nlid_likelihood_flow_fmnist_2 = visualize_scatterplot(\n    ax=axs[0],\n    artifact_dir=os.getenv(\"OOD_LID_LIKELIHOOD_FLOW_FMNIST_2\"),\n    title=\"Scatterplot on Flow FMNIST ($\\\\log \\\\tau=-5$)\",\n    alpha=0.6,\n)\n\nlid_likelihood_flow_mnist_2 = visualize_scatterplot(\n    ax=axs[1],\n    artifact_dir=os.getenv(\"OOD_LID_LIKELIHOOD_FLOW_MNIST_2\"),\n    title=\"Scatterplot on Flow MNIST ($\\\\log \\\\tau=-5$)\",\n    alpha=0.6,\n)\nplt.tight_layout(pad=1.0)\n# The hyperparameter setting is not good for diffusion models\nplt.show()\n\n\n\n\n\n\n\n\nFigure 5: Visualizing the scatterplot of LID and likelihood for in- and out-of-distribution data for normalizing flows at a different setting of \\tau where LID is always higher for in-distribution data.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection",
      "A Hands-on Guide"
    ]
  },
  {
    "objectID": "sections/ood/ood_guide.html#evaluating-ood-detection-results",
    "href": "sections/ood/ood_guide.html#evaluating-ood-detection-results",
    "title": "A Hands-on Guide",
    "section": "5 Evaluating OOD Detection Results",
    "text": "5 Evaluating OOD Detection Results\nWe finally show how to evaluate the OOD detection results. To do so, we will use the dual threshold algorithm, where a datapoint is in-distribution if it has both high likelihood and high LID values, which translates to larger probability mass around the datapoint. We have recorded the LID and likelihood estimates of the above scatterplots. Run the following script to evaluate the results:\n\n\nCode\nfrom metrics.ood.roc_analysis import get_roc_graph, get_pareto_frontier, get_auc\n\n\ndef get_aucs(results_dict):\n    ret = {}\n    likelihood_generated, lid_generated = results_dict[\"generated\"]\n    likelihood_in_distr, lid_in_distr = results_dict[\"in_distr_test\"]\n    likelihood_ood, lid_ood = results_dict[\"ood\"]\n\n    roc_x, roc_y = get_roc_graph(\n        pos_x=likelihood_in_distr,\n        neg_x=likelihood_ood,\n        verbose=0,\n    )\n    pareto_x, pareto_y = get_pareto_frontier(\n        roc_x, roc_y,\n    )\n    ret[\"Single Threshold (In-Distr vs. OOD)\"] = get_auc(pareto_x, pareto_y)\n    roc_x, roc_y = get_roc_graph(\n        pos_x=likelihood_generated,\n        neg_x=likelihood_ood,\n        verbose=0,\n    )\n    pareto_x, pareto_y = get_pareto_frontier(\n        roc_x, roc_y,\n    )\n    ret[\"Single Threshold (Generated vs. OOD)\"] = get_auc(pareto_x, pareto_y)\n\n    roc_x, roc_y = get_roc_graph(\n        pos_x=likelihood_in_distr,\n        pos_y=lid_in_distr,\n        neg_x=likelihood_ood,\n        neg_y=lid_ood,\n        verbose=0,\n    )\n    pareto_x, pareto_y = get_pareto_frontier(\n        roc_x, roc_y,\n    )\n    ret[\"Dual Threshold (In-Distr vs. OOD)\"] = get_auc(pareto_x, pareto_y)\n    roc_x, roc_y = get_roc_graph(\n        pos_x=likelihood_generated,\n        pos_y=lid_generated,\n        neg_x=likelihood_ood,\n        neg_y=lid_ood,\n        verbose=0,\n    )\n    pareto_x, pareto_y = get_pareto_frontier(\n        roc_x, roc_y,\n    )\n    ret[\"Dual Threshold (Generated vs. OOD)\"] = get_auc(pareto_x, pareto_y)\n    return ret\n\nrows = [\n    \"Single Threshold (In-Distr vs. OOD)\",\n    \"Dual Threshold (In-Distr vs. OOD)\",\n    \"Single Threshold (Generated vs. OOD)\",\n    \"Dual Threshold (Generated vs. OOD)\",\n]\ncolumns = [\n    (\"Normalizing flow [FMNIST vs. MNIST]\", lid_likelihood_flow_fmnist_1),\n    (\"Normalizing flow [MNIST vs. FMNIST]\", lid_likelihood_flow_mnist_1),\n    (\"Diffusion [FMNIST vs. MNIST]\", lid_likelihood_diffusion_fmnist_1),\n    (\"Diffusion [MNIST vs. FMNIST]\", lid_likelihood_diffusion_mnist_1),\n]\ndf = pd.DataFrame(index=rows, columns=[key for key, _ in columns])\n# create a \nfor key, auc_dict in columns:\n    for key2, value in get_aucs(auc_dict).items():\n        df.loc[key2, key] = value\ndf\n\n\n\n\n\n\n\n\n\nNormalizing flow [FMNIST vs. MNIST]\nNormalizing flow [MNIST vs. FMNIST]\nDiffusion [FMNIST vs. MNIST]\nDiffusion [MNIST vs. FMNIST]\n\n\n\n\nSingle Threshold (In-Distr vs. OOD)\n0.291138\n0.999207\n0.197205\n1.0\n\n\nDual Threshold (In-Distr vs. OOD)\n0.949707\n0.999207\n0.90802\n1.0\n\n\nSingle Threshold (Generated vs. OOD)\n0.228699\n0.999268\n0.0\n0.430664\n\n\nDual Threshold (Generated vs. OOD)\n0.951355\n0.999268\n0.948669\n0.436157\n\n\n\n\n\n\n\nAs you can see, the dual threshold algorithm is a simple yet effective way to detect OOD data. We also note that with this hyperparameter setup the Diffusion generated vs. OOD does not give us a good separation, however, by judiciously picking the \\tau value, we can get a good separation on that task too.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection",
      "A Hands-on Guide"
    ]
  },
  {
    "objectID": "sections/ood/ood_guide.html#extending-to-other-datasets",
    "href": "sections/ood/ood_guide.html#extending-to-other-datasets",
    "title": "A Hands-on Guide",
    "section": "6 Extending to Other Datasets",
    "text": "6 Extending to Other Datasets\nThroughout this notebook, we used FMNIST and MNIST as our illustrative datasets. However, you can easily extend this to other datasets by following the same steps above and would arrive at similar results. You can use our dataset to train on other image datasets as well, and we support them through our HuggingFace integration, we have already included the CIFAR10 and SVHN datasets in our codebase. Finally, while most of these observations have been made on image datasets, we also support training diffusion models and normalizing flows for tabular datasets in our codebase. However, the likelihood paradox is not as pronounced in tabular datasets as it is in image datasets.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection",
      "A Hands-on Guide"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Geometry of Deep Generative Models",
    "section": "",
    "text": "Here, we study how the geometry of deep generative models (DGMs) can inform our understanding of phenomena like memorization or be used for tasks like OOD detection. In tandem and as a supplement to these topics, we also study algorithms for local intrinsic dimension (LID) estimation of datapoints. Please navigate to our repository and run the following steps to get started."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "The Geometry of Deep Generative Models",
    "section": "1 Installation",
    "text": "1 Installation\nWe use a conda environment for this project. To create the environment, run:\n# this will create an environment named dgm_geometry:\nconda env create -f env.yaml\n# this will activate the environment:\nconda activate dgm_geometry\nFinally, download all the checkpoints, resources, and appropriate environment variables using the following:\npython scripts/download_resources.py\nYou may choose to skip this stage if you want to train your own models, but it is recommended as some of the notebooks use them."
  },
  {
    "objectID": "index.html#training-a-deep-generative-model",
    "href": "index.html#training-a-deep-generative-model",
    "title": "The Geometry of Deep Generative Models",
    "section": "2 Training a Deep Generative Model",
    "text": "2 Training a Deep Generative Model\nMost of the capabilities in the codebase involve using the training script, we use Pytorch Lightning for training and lightning callbacks for monitoring the behaviour and properties of the manifold induced by the generative model. Even when no training is involved, we use the training script but load checkpoints and set the epoch count to zero.\nTraining involves running scripts/train.py alongside a dataset and an experiment configuraton. To get started, you can run the following examples for training flows or diffusions on image datasets:\n# to train a greyscale diffusion, run the following! You can for example replace the dataset argument with mnist or fmnist\npython scripts/train.py dataset=&lt;grayscale-data&gt; +experiment=train_diffusion_greyscale\n# to train an RGB diffusion, run the following! You can for example replace the dataset argument with cifar10\npython scripts/train.py dataset=&lt;rgb-data&gt; +experiment=train_diffusion_rgb\n# to train a greyscale flow, run the following! You can for example replace the dataset argument with mnist or fmnist\npython scripts/train.py dataset=&lt;grayscale-data&gt; +experiment=train_flow_greyscale\n# to train an RGB flow, run the following! You can for example replace the dataset argument with cifar10\npython scripts/train.py dataset=&lt;rgb-data&gt; +experiment=train_flow_rgb\nFor example:\npython scripts/train.py dataset=mnist +experiment=train_diffusion_greyscale"
  },
  {
    "objectID": "index.html#our-work",
    "href": "index.html#our-work",
    "title": "The Geometry of Deep Generative Models",
    "section": "3 Our Work",
    "text": "3 Our Work\nThis repository contains code for reproducing the results in our papers “A geometric view of data complexity” (Kamkari, Ross, Hosseinzadeh, et al. 2024) and a geometric explanation of the likelihood OOD detection paradox (Kamkari, Ross, Cresswell, et al. 2024). You may cite our repository as follows:\n@misc{dgm_geometry_github,\n  author = {Hamidreza Kamkari, Brendan Leigh Ross, Jesse C. Cresswell, Gabriel Loaiza-Ganem},\n  title = {DGM Geometry},\n  year = {2024},\n  howpublished = {\\url{https://github.com/blross/dgm-geometry}},\n  note = {GitHub repository},\n}"
  },
  {
    "objectID": "sections/lid.html",
    "href": "sections/lid.html",
    "title": "Local Intrinsic Dimension Estimation",
    "section": "",
    "text": "1 Introduction\n\n\n\n\n\n\nFigure 1: An illustration showing that LID is a natural measure of relative complexity. We depict two manifolds of MNIST digits, corresponding to 1s and 8s, as 1d and 2d submanifolds of \\mathbb{R}^3, respectively. The relatively simpler manifold of 1s exhibits a single factor of variation (“tilt”), whereas 8s have an additional factor of variation (“disproportionality”).\n\n\n\nHigh-dimensional data in deep learning applications such as images often resides on low-dimensional submanifolds, which makes learning the properties of the learned manifold by a generative model a relevant problem (Loaiza-Ganem et al. 2024). One of the most important properties of a manifold is its intrinsic dimensionality which can loosely be defined as the number of factors of variation that describe the data. In reality, rather than having a single manifold representing the data distribution, we have a collection of manifolds (Brown et al. 2023) (or more recently the CW complex hypothesis (Wang and Wang, n.d.)) that describe the data distribution. Intuitively, this means that for example for a dataset of MNIST digits, the manifold of 1s and 8s are different, and they might have different intrinsic dimensionalities. Therefore, instead of (global) intrinsic dimensionality, we are interested at local intrinsic dimensionality (LID) which is a property of a point with respect to the manifold that contains it.\nVarious definitions of intrinsic dimension exist (Hurewicz and Wallman 1948), (Falconer 2007), (Lee 2012), we follow the standard one from geometry: a d-dimensional manifold is a set which is locally homeomorphic to \\mathbb{R}^d. For a given disjoint union of manifolds and a point x in this union, the of x is the dimension of the manifold it belongs to. Note that LID is not an intrinsic property of the point x, but rather a property of x with respect to the manifold that contains it. Intuitively, \\text{LID}(x) corresponds to the number of factors of variation present in the manifold containing x, and it is thus a natural measure of the relative complexity of x, as illustrated in Figure 1.\nComputing the LID for a given point is a complex task. Traditional non-parametric (or model-free) methods, such as those in the skdim-library (Bac et al. 2021), are computationally intensive and not scalable to high-dimensional data. Consequently, there is growing interest in using deep generative models for LID estimation. This approach is valuable not only for understanding the data manifold but also for evaluating the generative model itself. Discrepancies between the model-implied LID and the ground truth can highlight model deficiencies and help us to improve the quality of generative models. Here, we thoroughly explore LID methods for deep generative models with a particular focus on score-based diffusion models (Song et al. 2021), and explore their applications in trustworthy machine learning.\n\n\n2 What is LID Used For?\nLID estimates can be interpretated as a measure of complexity (Kamkari, Ross, Hosseinzadeh, et al. 2024) and can be useful in many scenarios. These estimates can also be used to detect outliers (Houle, Schubert, and Zimek 2018) (Anderberg et al. 2024) (Kamkari, Ross, Cresswell, et al. 2024), AI-generated text (Tulchinskii et al. 2023), and adversarial examples (Ma et al. 2018). Connections between the generalization achieved by a neural network and the LID estimates of its internal representations have also been shown (Ansuini et al. 2019), (Birdal et al. 2021), (Magai and Ayzenberg 2022), (Brown et al. 2022). These insights can be leveraged to identify which representations contain maximal semantic content (Valeriani et al. 2023), and help explain why LID estimates can be helpful as regularizers (Zhu et al. 2018) and for pruning large models (Xue et al. 2022). LID estimation is thus not only of mathematical and statistical interest, but can also benefit the empirical performance of deep learning models at numerous tasks.\n\n\n3 Useful links\nFor a guide on how to use our LID estimators, check out our notebook. We are also planning to release our latest work on using the Fokker-Planck equation of diffusion models to estimate LID, which we call FLIPD. When posted, it will show up here\n\n\n\n\n\n\n\nReferences\n\nAnderberg, Alastair, James Bailey, Ricardo JGB Campello, Michael E Houle, Henrique O Marques, Miloš Radovanović, and Arthur Zimek. 2024. “Dimensionality-Aware Outlier Detection.” In Proceedings of the 2024 SIAM International Conference on Data Mining, 652–60.\n\n\nAnsuini, Alessio, Alessandro Laio, Jakob H Macke, and Davide Zoccolan. 2019. “Intrinsic Dimension of Data Representations in Deep Neural Networks.” In Advances in Neural Information Processing Systems.\n\n\nBac, Jonathan, Evgeny M. Mirkes, Alexander N. Gorban, Ivan Tyukin, and Andrei Zinovyev. 2021. “Scikit-Dimension: A Python Package for Intrinsic Dimension Estimation.” Entropy 23 (10): 1368.\n\n\nBirdal, Tolga, Aaron Lou, Leonidas J Guibas, and Umut Simsekli. 2021. “Intrinsic Dimension, Persistent Homology and Generalization in Neural Networks.” In Advances in Neural Information Processing Systems.\n\n\nBrown, Bradley CA, Anthony L Caterini, Brendan Leigh Ross, Jesse C Cresswell, and Gabriel Loaiza-Ganem. 2023. “Verifying the Union of Manifolds Hypothesis for Image Data.” In International Conference on Learning Representations.\n\n\nBrown, Bradley CA, Jordan Juravsky, Anthony L Caterini, and Gabriel Loaiza-Ganem. 2022. “Relating Regularization and Generalization Through the Intrinsic Dimension of Activations.” arXiv:2211.13239.\n\n\nFalconer, Kenneth. 2007. Fractal Geometry: Mathematical Foundations and Applications. John Wiley & Sons.\n\n\nHoule, Michael E, Erich Schubert, and Arthur Zimek. 2018. “On the Correlation Between Local Intrinsic Dimensionality and Outlierness.” In Similarity Search and Applications: 11th International Conference, SISAP 2018, 177–91. Springer.\n\n\nHurewicz, Witold, and Henry Wallman. 1948. Dimension Theory (PMS-4). Princeton University Press.\n\n\nKamkari, Hamidreza, Brendan Leigh Ross, Jesse C Cresswell, Anthony L Caterini, Rahul G Krishnan, and Gabriel Loaiza-Ganem. 2024. “A Geometric Explanation of the Likelihood OOD Detection Paradox.” arXiv Preprint arXiv:2403.18910.\n\n\nKamkari, Hamidreza, Brendan Leigh Ross, Rasa Hosseinzadeh, Jesse C Cresswell, and Gabriel Loaiza-Ganem. 2024. “A Geometric View of Data Complexity: Efficient Local Intrinsic Dimension Estimation with Diffusion Models.” arXiv Preprint arXiv:2406.03537.\n\n\nLee, John M. 2012. Introduction to Smooth Manifolds. 2nd ed. Springer.\n\n\nLoaiza-Ganem, Gabriel, Brendan Leigh Ross, Rasa Hosseinzadeh, Anthony L Caterini, and Jesse C Cresswell. 2024. “Deep Generative Models Through the Lens of the Manifold Hypothesis: A Survey and New Connections.” arXiv Preprint arXiv:2404.02954.\n\n\nMa, Xingjun, Bo Li, Yisen Wang, Sarah M Erfani, Sudanthi Wijewickrema, Grant Schoenebeck, Dawn Song, Michael E Houle, and James Bailey. 2018. “Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality.” In International Conference on Learning Representations.\n\n\nMagai, German, and Anton Ayzenberg. 2022. “Topology and Geometry of Data Manifold in Deep Learning.” arXiv:2204.08624.\n\n\nSong, Yang, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. 2021. “Score-Based Generative Modeling Through Stochastic Differential Equations.” In International Conference on Learning Representations.\n\n\nTulchinskii, Eduard, Kristian Kuznetsov, Laida Kushnareva, Daniil Cherniavskii, Sergey Nikolenko, Evgeny Burnaev, Serguei Barannikov, and Irina Piontkovskaya. 2023. “Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts.” In Advances in Neural Information Processing Systems.\n\n\nValeriani, Lucrezia, Diego Doimo, Francesca Cuturello, Alessandro Laio, Alessio Ansuini, and Alberto Cazzaniga. 2023. “The Geometry of Hidden Representations of Large Transformer Models.” In Advances in Neural Information Processing Systems.\n\n\nWang, Yi, and Zhiren Wang. n.d. “CW Complex Hypothesis for Image Data.” In Forty-First International Conference on Machine Learning.\n\n\nXue, Fanghui, Biao Yang, Yingyong Qi, and Jack Xin. 2022. “Searching Intrinsic Dimensions of Vision Transformers.” arXiv:2204.07722.\n\n\nZhu, Wei, Qiang Qiu, Jiaji Huang, Robert Calderbank, Guillermo Sapiro, and Ingrid Daubechies. 2018. “LDMNet: Low Dimensional Manifold Regularized Neural Networks.” In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2743–51.",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension"
    ]
  },
  {
    "objectID": "sections/lid.html#references",
    "href": "sections/lid.html#references",
    "title": "Local Intrinsic Dimension Estimation",
    "section": "1 References –>",
    "text": "1 References –&gt;",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension"
    ]
  },
  {
    "objectID": "sections/ood/ood_guide.html#rthe-likelihood-paradox",
    "href": "sections/ood/ood_guide.html#rthe-likelihood-paradox",
    "title": "A Hands-on Guide",
    "section": "2 RThe likelihood paradox",
    "text": "2 RThe likelihood paradox\nWe first reproduce the likelihood OOD paradox, whereby the likelihood of OOD data, even though unseen during training, will be larger than that of in-distribution data. To do so, we can use the following commands to reproduce this for both flows and diffusions.\n# fmnist vs. mnist on flows\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_flow_greyscale +checkpoint=flow_fmnist +ood=flow_likelihood_paradox\n# mnist vs. fmnist on flows\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_flow_greyscale +checkpoint=flow_mnist +ood=flow_likelihood_paradox\n# fmnist vs. mnist on diffusions\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_fmnist +ood=diffusion_likelihood_paradox\n# mnist vs. fmnist on diffusions\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_mnist +ood=diffusion_likelihood_paradox\nYou may also add the extra options ood_subsample_size=&lt;x&gt; and ood_batch_size=&lt;x&gt; to control the number of samples used for OOD detection. The default values here are 4096 and 128, respectively. This is because the OOD detection for diffusions in particular can be computationally expensive, and we might need to subsample the OOD data to make it feasible.\nNote that we use the train.py script rather than a dedicated script for OOD detection. This is because the OOD detection is a simple extension of the training script, even when a checkpoint is unavailable, you can run the same script and it will train a model on the in-distribution data for the purpose of OOD detection. However, the most important reason of having it as an extension of train.py is that OOD detection using likelihoods, or as we will see, with LID, can be seen as monitoring different metrics of datapoints during training. Therefore, we implement it as a callback that can be used during training. We can then compose multiple callbacks to monitor different metrics, such as the likelihood of the data, the LID of the data, etc.\nBefore moving on, let us visualize the likelihoods that we obtain. Every script will create an mlflow experiment with an appropriate mlflow artifacts directory. The artifacts should lie in outputs/mlruns/??/??/artifacts/ and you can visualize them using the mlflow console as well. When moving to the logs of each of these runs, you will notice the following directories:\n\nsamples_grid/xxx.png: contains samples produced by the generative model and serves as a sanity check.\nlikelihood_in_distr_train/: This contains the monitoring results of the in-distribution data from the training set.\nlikelihood_in_distr_test/: This contains the monitoring results of the in-distribution data from the test set.\nlikelihood_ood/: This contains the monitoring results of the OOD data.\nlikelihood_generated/: This contains the monitoring results of the generated data.\n\nEach of these directories contains a metrics=xxx.csv file with a column labelled as LikelihoodMetric that contains the likelihoods of the data. We can use these likelihoods to visualize the likelihood paradox. Moreover, there is a samples/idx.png for idx ranging over the number of samples that we have used for monitoring. We can use these samples to visualize and have access to the samples that have been used for monitoring.\nNext, we store the artifact directory in our .env folder:\ndotenv set OOD_LIKELIHOOD_PARADOX_FLOW_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_FLOW_MNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_DIFFUSION_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_DIFFUSION_MNIST &lt;corresponding_artifact_dir&gt;\nNote that if you have used our download_resources.py script, the results should be stored in the .env file already with some artifact directories that we have already used. Therefore, you can skip the step of generating these artifacts if the script takes too long to run on your machine. In fact, this pattern will be repeated for the rest of the notebook, where we introduce the set of commands to generate artifacts, and we also store our own runs already in the .env file if you have used the download_resources.py script.\nNow, use the following cell to visualize the content in these tables. It will visualize 4 different plots showing the histogram of likelihoods for OOD samples, in-distribution (test and train split), and also, the generated samples (in gold). We see the peculiar behaviour on the generated samples’ likelihoods as well which is always smaller than the in-distribution samples.\n\n\nCode\n%autoreload 2\nimport dotenv\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom visualization.pretty import ColorTheme\n# load the environment variables\ndotenv.load_dotenv(override=True)\nimport os\n\ndef visualize_likelihood_ood(ax, artifact_dir: str, title: str, bins: int = 100):\n    # find the directory {artifact_dir}/likelihood_generated/metrics=xxx.csv`\n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_generated\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_generated = pd.read_csv(metrics_dir)['LikelihoodMetric']\n\n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_ood\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_ood = pd.read_csv(metrics_dir)['LikelihoodMetric']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_in_distr_train\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_train = pd.read_csv(os.path.join(artifact_dir, metrics_dir))['LikelihoodMetric']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_in_distr_test\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_test = pd.read_csv(os.path.join(artifact_dir, metrics_dir))['LikelihoodMetric']\n\n    # plot an overlapping histogram\n    ax.hist(likelihood_generated, bins=bins, alpha=0.5, label=\"Generated\", density=True, color=ColorTheme.GOLD.value)\n    ax.hist(likelihood_ood, bins=bins, alpha=0.5, label=\"OOD\", density=True, color=ColorTheme.RED_FIRST.value)\n    ax.hist(likelihood_in_distr_train, bins=bins, alpha=0.5, label=\"In-distribution train\", density=True, color=ColorTheme.BLUE_FIRST.value)\n    ax.hist(likelihood_in_distr_test, bins=bins, alpha=0.5, label=\"In-distribution test\", density=True, color=ColorTheme.BLUE_SECOND.value)\n    ax.set_title(title)\n    ax.legend()\n\nfig, axs = plt.subplots(2, 2, figsize=(8, 6))\n\nvisualize_likelihood_ood(\n    ax=axs[0, 0],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_FLOW_FMNIST\"),\n    title=\"Paradoxical Flow Fashion FMNIST vs. MNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[0, 1],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_FLOW_MNIST\"),\n    title=\"Non-Paradoxical Flow MNIST vs. FMNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[1, 0],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_DIFFUSION_FMNIST\"),\n    title=\"Paradoxical Diffusion FMNIST vs. MNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[1, 1],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_DIFFUSION_MNIST\"),\n    title=\"Non-Paradoxical Diffusion MNIST vs. FMNIST\",\n    bins=66,\n)\n# Adjust layout and spacing\nplt.tight_layout(pad=1.0)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: The likelihood OOD paradox visualized in both FMNIST- and MNIST-trained models for normalizing flows and diffusion models.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection",
      "A Hands-on Guide"
    ]
  },
  {
    "objectID": "sections/ood/ood_guide.html#reproducithe-likelihood-paradox",
    "href": "sections/ood/ood_guide.html#reproducithe-likelihood-paradox",
    "title": "A Hands-on Guide",
    "section": "2 ReproduciThe likelihood paradox",
    "text": "2 ReproduciThe likelihood paradox\nWe first reproduce the likelihood OOD paradox, whereby the likelihood of OOD data, even though unseen during training, will be larger than that of in-distribution data. To do so, we can use the following commands to reproduce this for both flows and diffusions.\n# fmnist vs. mnist on flows\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_flow_greyscale +checkpoint=flow_fmnist +ood=flow_likelihood_paradox\n# mnist vs. fmnist on flows\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_flow_greyscale +checkpoint=flow_mnist +ood=flow_likelihood_paradox\n# fmnist vs. mnist on diffusions\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_fmnist +ood=diffusion_likelihood_paradox\n# mnist vs. fmnist on diffusions\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_mnist +ood=diffusion_likelihood_paradox\nYou may also add the extra options ood_subsample_size=&lt;x&gt; and ood_batch_size=&lt;x&gt; to control the number of samples used for OOD detection. The default values here are 4096 and 128, respectively. This is because the OOD detection for diffusions in particular can be computationally expensive, and we might need to subsample the OOD data to make it feasible.\nNote that we use the train.py script rather than a dedicated script for OOD detection. This is because the OOD detection is a simple extension of the training script, even when a checkpoint is unavailable, you can run the same script and it will train a model on the in-distribution data for the purpose of OOD detection. However, the most important reason of having it as an extension of train.py is that OOD detection using likelihoods, or as we will see, with LID, can be seen as monitoring different metrics of datapoints during training. Therefore, we implement it as a callback that can be used during training. We can then compose multiple callbacks to monitor different metrics, such as the likelihood of the data, the LID of the data, etc.\nBefore moving on, let us visualize the likelihoods that we obtain. Every script will create an mlflow experiment with an appropriate mlflow artifacts directory. The artifacts should lie in outputs/mlruns/??/??/artifacts/ and you can visualize them using the mlflow console as well. When moving to the logs of each of these runs, you will notice the following directories:\n\nsamples_grid/xxx.png: contains samples produced by the generative model and serves as a sanity check.\nlikelihood_in_distr_train/: This contains the monitoring results of the in-distribution data from the training set.\nlikelihood_in_distr_test/: This contains the monitoring results of the in-distribution data from the test set.\nlikelihood_ood/: This contains the monitoring results of the OOD data.\nlikelihood_generated/: This contains the monitoring results of the generated data.\n\nEach of these directories contains a metrics=xxx.csv file with a column labelled as LikelihoodMetric that contains the likelihoods of the data. We can use these likelihoods to visualize the likelihood paradox. Moreover, there is a samples/idx.png for idx ranging over the number of samples that we have used for monitoring. We can use these samples to visualize and have access to the samples that have been used for monitoring.\nNext, we store the artifact directory in our .env folder:\ndotenv set OOD_LIKELIHOOD_PARADOX_FLOW_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_FLOW_MNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_DIFFUSION_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_DIFFUSION_MNIST &lt;corresponding_artifact_dir&gt;\nNote that if you have used our download_resources.py script, the results should be stored in the .env file already with some artifact directories that we have already used. Therefore, you can skip the step of generating these artifacts if the script takes too long to run on your machine. In fact, this pattern will be repeated for the rest of the notebook, where we introduce the set of commands to generate artifacts, and we also store our own runs already in the .env file if you have used the download_resources.py script.\nNow, use the following cell to visualize the content in these tables. It will visualize 4 different plots showing the histogram of likelihoods for OOD samples, in-distribution (test and train split), and also, the generated samples (in gold). We see the peculiar behaviour on the generated samples’ likelihoods as well which is always smaller than the in-distribution samples.\n\n\nCode\n%autoreload 2\nimport dotenv\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom visualization.pretty import ColorTheme\n# load the environment variables\ndotenv.load_dotenv(override=True)\nimport os\n\ndef visualize_likelihood_ood(ax, artifact_dir: str, title: str, bins: int = 100):\n    # find the directory {artifact_dir}/likelihood_generated/metrics=xxx.csv`\n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_generated\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_generated = pd.read_csv(metrics_dir)['LikelihoodMetric']\n\n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_ood\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_ood = pd.read_csv(metrics_dir)['LikelihoodMetric']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_in_distr_train\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_train = pd.read_csv(os.path.join(artifact_dir, metrics_dir))['LikelihoodMetric']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_in_distr_test\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_test = pd.read_csv(os.path.join(artifact_dir, metrics_dir))['LikelihoodMetric']\n\n    # plot an overlapping histogram\n    ax.hist(likelihood_generated, bins=bins, alpha=0.5, label=\"Generated\", density=True, color=ColorTheme.GOLD.value)\n    ax.hist(likelihood_ood, bins=bins, alpha=0.5, label=\"OOD\", density=True, color=ColorTheme.RED_FIRST.value)\n    ax.hist(likelihood_in_distr_train, bins=bins, alpha=0.5, label=\"In-distribution train\", density=True, color=ColorTheme.BLUE_FIRST.value)\n    ax.hist(likelihood_in_distr_test, bins=bins, alpha=0.5, label=\"In-distribution test\", density=True, color=ColorTheme.BLUE_SECOND.value)\n    ax.set_title(title)\n    ax.legend()\n\nfig, axs = plt.subplots(2, 2, figsize=(8, 6))\n\nvisualize_likelihood_ood(\n    ax=axs[0, 0],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_FLOW_FMNIST\"),\n    title=\"Paradoxical Flow Fashion FMNIST vs. MNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[0, 1],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_FLOW_MNIST\"),\n    title=\"Non-Paradoxical Flow MNIST vs. FMNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[1, 0],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_DIFFUSION_FMNIST\"),\n    title=\"Paradoxical Diffusion FMNIST vs. MNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[1, 1],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_DIFFUSION_MNIST\"),\n    title=\"Non-Paradoxical Diffusion MNIST vs. FMNIST\",\n    bins=66,\n)\n# Adjust layout and spacing\nplt.tight_layout(pad=1.0)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: The likelihood OOD paradox visualized in both FMNIST- and MNIST-trained models for normalizing flows and diffusion models.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection",
      "A Hands-on Guide"
    ]
  },
  {
    "objectID": "sections/ood/ood_guide.html#reproducing-the-likelihood-paradox",
    "href": "sections/ood/ood_guide.html#reproducing-the-likelihood-paradox",
    "title": "A Hands-on Guide",
    "section": "2 Reproducing the Likelihood Paradox",
    "text": "2 Reproducing the Likelihood Paradox\nWe first reproduce the likelihood OOD paradox, whereby the likelihood of OOD data, even though unseen during training, will be larger than that of in-distribution data. To do so, run the following commands that will evaluate the likelihoods of a dataset onto a model that has either been trained on FMNIST or MNIST.\n# fmnist vs. mnist on flows\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_flow_greyscale +checkpoint=flow_fmnist +ood=flow_likelihood_paradox\n# mnist vs. fmnist on flows\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_flow_greyscale +checkpoint=flow_mnist +ood=flow_likelihood_paradox\n# fmnist vs. mnist on diffusions\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_fmnist +ood=diffusion_likelihood_paradox\n# mnist vs. fmnist on diffusions\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_mnist +ood=diffusion_likelihood_paradox\nLikelihood computation for diffusion models can take some time. Thus, you may also add the extra options ood_subsample_size=&lt;x&gt; and ood_batch_size=&lt;x&gt; to control the number of samples where we evaluate likelihood for. The default values here are 4096 and 128, respectively, but you may set it to for example ood_subsample_size=128 and ood_batch_size=8 to speed up the process.\nNote that we use the train.py script rather than a dedicated script for OOD detection. This is because the OOD detection is a simple extension of the training script, even when a checkpoint is unavailable, you can run the same script and it will train a model on the in-distribution data for the purpose of OOD detection. We also implement OOD detection as a lightning callback, which is another reason why we stick to this abstraction.\nBefore moving on, let us visualize the likelihoods that we obtained to see if the paradox holds. Every script will create an mlflow experiment with an appropriate mlflow artifacts directory. The artifacts should lie in outputs/mlruns/??/??/artifacts/ and you can visualize them using the mlflow console as well. When moving to the artifacts directory of each of these runs, you will notice the following directories:\n\nsamples_grid/xxx.png: contains samples produced by the generative model and serves as a sanity check.\nlikelihood_in_distr_train/: This contains the monitoring results of the in-distribution data from the training set.\nlikelihood_in_distr_test/: This contains the monitoring results of the in-distribution data from the test set.\nlikelihood_ood/: This contains the monitoring results of the OOD data.\nlikelihood_generated/: This contains the monitoring results of the generated data.\n\nEach of these directories contains a metrics=xxx.csv file with a column labelled as LikelihoodMetric that contains the likelihoods of each datapoint in its rows. We can use these likelihoods to visualize the likelihood paradox. Please store these artifact directories in your .env file using the following commands:\ndotenv set OOD_LIKELIHOOD_PARADOX_FLOW_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_FLOW_MNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_DIFFUSION_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_DIFFUSION_MNIST &lt;corresponding_artifact_dir&gt;\nIf you look at your .env file before running the above commands, you will noticve that we have already some preset values for these artifact directories, and if you have run the download_resources.py script, you should have these artifact directories already stored in your machine. Now, use the following cell to visualize the content in these tables. It will visualize 4 different plots showing the histogram of likelihoods for OOD samples, in-distribution (test and train split), and also, the generated samples (in gold). We see the peculiar behaviour on the generated samples’ likelihoods as well which is always smaller than the in-distribution samples.\n\n\nCode\n%autoreload 2\nimport dotenv\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom visualization.pretty import ColorTheme\n# load the environment variables\ndotenv.load_dotenv(override=True)\nimport os\n\ndef visualize_likelihood_ood(ax, artifact_dir: str, title: str, bins: int = 100):\n    # find the directory {artifact_dir}/likelihood_generated/metrics=xxx.csv`\n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_generated\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_generated = pd.read_csv(metrics_dir)['LikelihoodMetric']\n\n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_ood\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_ood = pd.read_csv(metrics_dir)['LikelihoodMetric']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_in_distr_train\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_train = pd.read_csv(os.path.join(artifact_dir, metrics_dir))['LikelihoodMetric']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_in_distr_test\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_test = pd.read_csv(os.path.join(artifact_dir, metrics_dir))['LikelihoodMetric']\n\n    # plot an overlapping histogram\n    ax.hist(likelihood_generated, bins=bins, alpha=0.5, label=\"Generated\", density=True, color=ColorTheme.GOLD.value)\n    ax.hist(likelihood_ood, bins=bins, alpha=0.5, label=\"OOD\", density=True, color=ColorTheme.RED_FIRST.value)\n    ax.hist(likelihood_in_distr_train, bins=bins, alpha=0.5, label=\"In-distribution train\", density=True, color=ColorTheme.BLUE_FIRST.value)\n    ax.hist(likelihood_in_distr_test, bins=bins, alpha=0.5, label=\"In-distribution test\", density=True, color=ColorTheme.BLUE_SECOND.value)\n    ax.set_title(title)\n    ax.legend()\n\nfig, axs = plt.subplots(2, 2, figsize=(8, 6))\n\nvisualize_likelihood_ood(\n    ax=axs[0, 0],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_FLOW_FMNIST\"),\n    title=\"Paradoxical Flow Fashion FMNIST vs. MNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[0, 1],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_FLOW_MNIST\"),\n    title=\"Non-Paradoxical Flow MNIST vs. FMNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[1, 0],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_DIFFUSION_FMNIST\"),\n    title=\"Paradoxical Diffusion FMNIST vs. MNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[1, 1],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_DIFFUSION_MNIST\"),\n    title=\"Non-Paradoxical Diffusion MNIST vs. FMNIST\",\n    bins=66,\n)\n# Adjust layout and spacing\nplt.tight_layout(pad=1.0)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: The likelihood OOD paradox visualized in both FMNIST- and MNIST-trained models for normalizing flows and diffusion models.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection",
      "A Hands-on Guide"
    ]
  },
  {
    "objectID": "sections/ood/ood_guide.html#reproducing-the-ikelihood-paradox",
    "href": "sections/ood/ood_guide.html#reproducing-the-ikelihood-paradox",
    "title": "A Hands-on Guide",
    "section": "2 Reproducing the ikelihood paradox",
    "text": "2 Reproducing the ikelihood paradox\nWe first reproduce the likelihood OOD paradox, whereby the likelihood of OOD data, even though unseen during training, will be larger than that of in-distribution data. To do so, we can use the following commands to reproduce this for both flows and diffusions.\n# fmnist vs. mnist on flows\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_flow_greyscale +checkpoint=flow_fmnist +ood=flow_likelihood_paradox\n# mnist vs. fmnist on flows\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_flow_greyscale +checkpoint=flow_mnist +ood=flow_likelihood_paradox\n# fmnist vs. mnist on diffusions\npython scripts/train.py dataset=fmnist +dataset_ood=mnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_fmnist +ood=diffusion_likelihood_paradox\n# mnist vs. fmnist on diffusions\npython scripts/train.py dataset=mnist +dataset_ood=fmnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_mnist +ood=diffusion_likelihood_paradox\nYou may also add the extra options ood_subsample_size=&lt;x&gt; and ood_batch_size=&lt;x&gt; to control the number of samples used for OOD detection. The default values here are 4096 and 128, respectively. This is because the OOD detection for diffusions in particular can be computationally expensive, and we might need to subsample the OOD data to make it feasible.\nNote that we use the train.py script rather than a dedicated script for OOD detection. This is because the OOD detection is a simple extension of the training script, even when a checkpoint is unavailable, you can run the same script and it will train a model on the in-distribution data for the purpose of OOD detection. However, the most important reason of having it as an extension of train.py is that OOD detection using likelihoods, or as we will see, with LID, can be seen as monitoring different metrics of datapoints during training. Therefore, we implement it as a callback that can be used during training. We can then compose multiple callbacks to monitor different metrics, such as the likelihood of the data, the LID of the data, etc.\nBefore moving on, let us visualize the likelihoods that we obtain. Every script will create an mlflow experiment with an appropriate mlflow artifacts directory. The artifacts should lie in outputs/mlruns/??/??/artifacts/ and you can visualize them using the mlflow console as well. When moving to the logs of each of these runs, you will notice the following directories:\n\nsamples_grid/xxx.png: contains samples produced by the generative model and serves as a sanity check.\nlikelihood_in_distr_train/: This contains the monitoring results of the in-distribution data from the training set.\nlikelihood_in_distr_test/: This contains the monitoring results of the in-distribution data from the test set.\nlikelihood_ood/: This contains the monitoring results of the OOD data.\nlikelihood_generated/: This contains the monitoring results of the generated data.\n\nEach of these directories contains a metrics=xxx.csv file with a column labelled as LikelihoodMetric that contains the likelihoods of the data. We can use these likelihoods to visualize the likelihood paradox. Moreover, there is a samples/idx.png for idx ranging over the number of samples that we have used for monitoring. We can use these samples to visualize and have access to the samples that have been used for monitoring.\nNext, we store the artifact directory in our .env folder:\ndotenv set OOD_LIKELIHOOD_PARADOX_FLOW_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_FLOW_MNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_DIFFUSION_FMNIST &lt;corresponding_artifact_dir&gt;\ndotenv set OOD_LIKELIHOOD_PARADOX_DIFFUSION_MNIST &lt;corresponding_artifact_dir&gt;\nNote that if you have used our download_resources.py script, the results should be stored in the .env file already with some artifact directories that we have already used. Therefore, you can skip the step of generating these artifacts if the script takes too long to run on your machine. In fact, this pattern will be repeated for the rest of the notebook, where we introduce the set of commands to generate artifacts, and we also store our own runs already in the .env file if you have used the download_resources.py script.\nNow, use the following cell to visualize the content in these tables. It will visualize 4 different plots showing the histogram of likelihoods for OOD samples, in-distribution (test and train split), and also, the generated samples (in gold). We see the peculiar behaviour on the generated samples’ likelihoods as well which is always smaller than the in-distribution samples.\n\n\nCode\n%autoreload 2\nimport dotenv\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom visualization.pretty import ColorTheme\n# load the environment variables\ndotenv.load_dotenv(override=True)\nimport os\n\ndef visualize_likelihood_ood(ax, artifact_dir: str, title: str, bins: int = 100):\n    # find the directory {artifact_dir}/likelihood_generated/metrics=xxx.csv`\n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_generated\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_generated = pd.read_csv(metrics_dir)['LikelihoodMetric']\n\n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_ood\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_ood = pd.read_csv(metrics_dir)['LikelihoodMetric']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_in_distr_train\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_train = pd.read_csv(os.path.join(artifact_dir, metrics_dir))['LikelihoodMetric']\n    \n    likelihood_dir = os.path.join(artifact_dir, \"likelihood_in_distr_test\")\n    metrics_dir = [f for f in os.listdir(likelihood_dir) if f.startswith(\"metrics\")][0]\n    metrics_dir = os.path.join(likelihood_dir, metrics_dir)\n    likelihood_in_distr_test = pd.read_csv(os.path.join(artifact_dir, metrics_dir))['LikelihoodMetric']\n\n    # plot an overlapping histogram\n    ax.hist(likelihood_generated, bins=bins, alpha=0.5, label=\"Generated\", density=True, color=ColorTheme.GOLD.value)\n    ax.hist(likelihood_ood, bins=bins, alpha=0.5, label=\"OOD\", density=True, color=ColorTheme.RED_FIRST.value)\n    ax.hist(likelihood_in_distr_train, bins=bins, alpha=0.5, label=\"In-distribution train\", density=True, color=ColorTheme.BLUE_FIRST.value)\n    ax.hist(likelihood_in_distr_test, bins=bins, alpha=0.5, label=\"In-distribution test\", density=True, color=ColorTheme.BLUE_SECOND.value)\n    ax.set_title(title)\n    ax.legend()\n\nfig, axs = plt.subplots(2, 2, figsize=(8, 6))\n\nvisualize_likelihood_ood(\n    ax=axs[0, 0],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_FLOW_FMNIST\"),\n    title=\"Paradoxical Flow Fashion FMNIST vs. MNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[0, 1],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_FLOW_MNIST\"),\n    title=\"Non-Paradoxical Flow MNIST vs. FMNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[1, 0],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_DIFFUSION_FMNIST\"),\n    title=\"Paradoxical Diffusion FMNIST vs. MNIST\",\n    bins=66,\n)\nvisualize_likelihood_ood(\n    ax=axs[1, 1],\n    artifact_dir=os.getenv(\"OOD_LIKELIHOOD_PARADOX_DIFFUSION_MNIST\"),\n    title=\"Non-Paradoxical Diffusion MNIST vs. FMNIST\",\n    bins=66,\n)\n# Adjust layout and spacing\nplt.tight_layout(pad=1.0)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: The likelihood OOD paradox visualized in both FMNIST- and MNIST-trained models for normalizing flows and diffusion models.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection",
      "A Hands-on Guide"
    ]
  },
  {
    "objectID": "sections/ood.html",
    "href": "sections/ood.html",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "",
    "text": "Figure 1: The likelihood assigned to OOD datapoints (in red) is higher than both the likelihoods assigned to in-distribution datapoints (in blue), as well as samples generated from the model (in gold).",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#how-does-it-relate-to-prior-work",
    "href": "sections/ood.html#how-does-it-relate-to-prior-work",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "3 How does it relate to prior work?",
    "text": "3 How does it relate to prior work?\nsth sth\nsads",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#intr",
    "href": "sections/ood.html#intr",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "1 Intr",
    "text": "1 Intr\nIntuitively, when one trains a likelihood-based generative model, it implicitly or explicitly increases the likelihood for the training (in-distribution) data. Therefore, it is reasonable to assume that since the likelihoods integrate to zero (likelihoods are in fact a valid probability density p_\\theta) out-of-distribution (OOD) data would obtain low likelihoods. However, paradoxically, deep generative models do not show this behaviour. In fact, based on the research presented in “Do deep generative models know what they don’t know?” (Nalisnick et al. 2019), OOD datapoints sometimes consistently get assigned higher likelihoods than in-distribution data. This phenomenon, which is coined the Likelihood Paradox, is not only a significant challenge for OOD detection, but also a fundamental question about the nature of deep generative models. Figure 1 illustrates this phenomenon for a generative model, whereby the model is trained on FMNIST but assigns higher likelihoods to MNIST digits (in red) that it has never seen before! Adding to the perplexity, the model never generates things that are even remotely similar to MNIST digits, as depicted in Figure 1.\nIn our study (Kamkari et al. 2024), we facilitate the simple observation that while generative models assign high probability density to OOD data, the probability mass assigned to the OOD manifold is almost zero. Otherwise, the model would sometimes generate OOD datapoints, which is not the case. In turn, rather than relying on likelihoods alone, we should use extra informatioin that reveals characteristics of the probability mass. For example, when OOD data is supported on an extremely low-dimensional manifold, then no matter how high the probability density is, the probability mass assigned to the OOD manifold is almost zero. This observation is the basis of our proposed method, which we call Out-of-Distribution Detection with Local Intrinsic Dimensionality (OOD-LID).",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#introduction",
    "href": "sections/ood.html#introduction",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "1 Introduction",
    "text": "1 Introduction\nIntuitively, when one trains a likelihood-based generative model, it implicitly or explicitly increases the likelihood for the training (in-distribution) data. Therefore, it is reasonable to assume that since the likelihoods integrate to zero (likelihoods are in fact a valid probability density p_\\theta) out-of-distribution (OOD) data would obtain low likelihoods. However, paradoxically, deep generative models do not show this behaviour. In fact, based on the research presented in “Do deep generative models know what they don’t know?” (Nalisnick et al. 2019), OOD datapoints sometimes consistently get assigned higher likelihoods than in-distribution data. This phenomenon, which is coined the Likelihood Paradox, is not only a significant challenge for OOD detection, but also a fundamental question about the nature of deep generative models. Figure 1 illustrates this phenomenon for a generative model, whereby the model is trained on FMNIST but assigns higher likelihoods to MNIST digits (in red) that it has never seen before! Adding to the perplexity, the model never generates things that are even remotely similar to MNIST digits, as depicted in Figure 1.\nIn our study (Kamkari, Ross, Cresswell, et al. 2024), we facilitate the simple observation that while generative models assign high probability density to OOD data, the probability mass assigned to the OOD manifold is almost zero. Otherwise, the model would sometimes generate OOD datapoints, which is not the case. In turn, rather than relying on likelihoods alone, we should use extra informatioin that reveals characteristics of the probability mass. For example, when OOD data is supported on an extremely low-dimensional manifold, then no matter how high the probability density is, the probability mass assigned to the OOD manifold is almost zero. This observation is the basis of our proposed method, which we call Out-of-Distribution Detection with Local Intrinsic Dimensionality (OOD-LID).",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#introduction-of",
    "href": "sections/ood.html#introduction-of",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "1 Introduction of",
    "text": "1 Introduction of\nIntuitively, when one trains a likelihood-based generative model, it implicitly or explicitly increases the likelihood for the training (in-distribution) data. Therefore, it is reasonable to assume that since the likelihoods integrate to zero (likelihoods are in fact a valid probability density p_\\theta) out-of-distribution (OOD) data would obtain low likelihoods. However, paradoxically, deep generative models do not show this behaviour. In fact, based on the research presented in “Do deep generative models know what they don’t know?” (Nalisnick et al. 2019), OOD datapoints sometimes consistently get assigned higher likelihoods than in-distribution data. This phenomenon, which is coined the Likelihood Paradox, is not only a significant challenge for OOD detection, but also a fundamental question about the nature of deep generative models. Figure 1 illustrates this phenomenon for a generative model, whereby the model is trained on FMNIST but assigns higher likelihoods to MNIST digits (in red) that it has never seen before! Adding to the perplexity, the model never generates things that are even remotely similar to MNIST digits, as depicted in Figure 1.\nIn our study (Kamkari et al. 2024), we facilitate the simple observation that while generative models assign high probability density to OOD data, the probability mass assigned to the OOD manifold is almost zero. Otherwise, the model would sometimes generate OOD datapoints, which is not the case. In turn, rather than relying on likelihoods alone, we should use extra informatioin that reveals characteristics of the probability mass. For example, when OOD data is supported on an extremely low-dimensional manifold, then no matter how high the probability density is, the probability mass assigned to the OOD manifold is almost zero. This observation is the basis of our proposed method, which we call Out-of-Distribution Detection with Local Intrinsic Dimensionality (OOD-LID).",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#introduction-of-t",
    "href": "sections/ood.html#introduction-of-t",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "1 Introduction of t",
    "text": "1 Introduction of t\nIntuitively, when one trains a likelihood-based generative model, it implicitly or explicitly increases the likelihood for the training (in-distribution) data. Therefore, it is reasonable to assume that since the likelihoods integrate to zero (likelihoods are in fact a valid probability density p_\\theta) out-of-distribution (OOD) data would obtain low likelihoods. However, paradoxically, deep generative models do not show this behaviour. In fact, based on the research presented in “Do deep generative models know what they don’t know?” (Nalisnick et al. 2019), OOD datapoints sometimes consistently get assigned higher likelihoods than in-distribution data. This phenomenon, which is coined the Likelihood Paradox, is not only a significant challenge for OOD detection, but also a fundamental question about the nature of deep generative models. Figure 1 illustrates this phenomenon for a generative model, whereby the model is trained on FMNIST but assigns higher likelihoods to MNIST digits (in red) that it has never seen before! Adding to the perplexity, the model never generates things that are even remotely similar to MNIST digits, as depicted in Figure 1.\nIn our study (Kamkari et al. 2024), we facilitate the simple observation that while generative models assign high probability density to OOD data, the probability mass assigned to the OOD manifold is almost zero. Otherwise, the model would sometimes generate OOD datapoints, which is not the case. In turn, rather than relying on likelihoods alone, we should use extra informatioin that reveals characteristics of the probability mass. For example, when OOD data is supported on an extremely low-dimensional manifold, then no matter how high the probability density is, the probability mass assigned to the OOD manifold is almost zero. This observation is the basis of our proposed method, which we call Out-of-Distribution Detection with Local Intrinsic Dimensionality (OOD-LID).",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#section",
    "href": "sections/ood.html#section",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "2 ",
    "text": "2",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#a",
    "href": "sections/ood.html#a",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "2 A",
    "text": "2 A",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#a-simp",
    "href": "sections/ood.html#a-simp",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "2 A simp",
    "text": "2 A simp",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#a-c",
    "href": "sections/ood.html#a-c",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "2 A C",
    "text": "2 A C",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#a-cartoon-ill",
    "href": "sections/ood.html#a-cartoon-ill",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "2 A Cartoon Ill",
    "text": "2 A Cartoon Ill",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#a-cartoon-illustrate",
    "href": "sections/ood.html#a-cartoon-illustrate",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "2 A Cartoon illustrate",
    "text": "2 A Cartoon illustrate",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#a-cartoon-illustra",
    "href": "sections/ood.html#a-cartoon-illustra",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "2 A Cartoon illustra",
    "text": "2 A Cartoon illustra",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#a-cartoon-illustration",
    "href": "sections/ood.html#a-cartoon-illustration",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "2 A Cartoon Illustration",
    "text": "2 A Cartoon Illustration\n\n\n\n\n\n\nFigure 2: Illustrating the likelihood paradox between FMNIST (the blue region) and MNIST (the red region): Despite the model not having seen MNIST images before, the density (shown in gold) peaks at MNIST, yet it never generates samples from it. By using LID as a tractable proxy for volume, we argue that a region is considered in-distribution not just because it has high density, but because it has both high density and high volume.\n\n\n\nOur explanation for the likelihood paradox is as follows: While paradoxical out-of-distribution regions might exist due to the complexity of deep generative models, the fact that the model never generates them indicates that they must have low probability mass. Calculating probability mass directly is intractable for complex regions in high-dimensional spaces. Instead, we can intuitively think of the probability mass as the volume of the region multiplied by the probability density. Although computing the volume of a small region too is challenging, we establish that this volume is monotonically related to the intrinsic dimensionality of the region, for which we have estimators.\nTherefore, we propose using the intrinsic dimensionality of the region as a proxy for its probability mass. When a manifold has lower intrinsic dimensionality than another, its volume is infinitely smaller, and thus, its probability mass is also infinitely smaller. Drawing an analogy, we hypothesize that these paradoxical likelihood regions lie on lower-dimensional manifolds. Consequently, even though the probability density might be high, the probability mass is infinitely small.\nWe have illustrated our point in Figure 2. The cartoon shows a model trained on FMNIST and assumes FMNIST lies on a higher-dimensional manifold (in blue) than MNIST (in red). The model assigns higher likelihoods to MNIST digits, which are OOD, but because the volume of the MNIST region is infinitely smaller due to its lower intrinsic dimensionality, the probability mass assigned to the MNIST manifold is almost zero. Therefore, the model never generates MNIST digits.\nLeveraging this observation, we design a simple yet effective OOD detection algorithm: estimate both the likelihood and intrinsic dimensionality for each datapoint and classify a datapoint as in-distribution if and only if both the likelihood and intrinsic dimensionality are high (above certain thresholds \\psi_{\\mathcal{L}} and \\psi_{\\text{LID}_\\theta} on likelihood and LID, respectively). As depicted in Figure 2, this method will (1) classify pure noise as OOD because it has low likelihood, (2) classify MNIST as OOD because despite having high likelihood, it has low intrinsic dimensionality, and (3) classify FMNIST as in-distribution because it has both high likelihood and high intrinsic dimensionality.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#r",
    "href": "sections/ood.html#r",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "3 R",
    "text": "3 R\nsth sth\nsads",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#relation-to-prior",
    "href": "sections/ood.html#relation-to-prior",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "3 Relation to Prior",
    "text": "3 Relation to Prior\nsth sth\nsads",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#relation-to-prior-work",
    "href": "sections/ood.html#relation-to-prior-work",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "3 Relation to Prior Work",
    "text": "3 Relation to Prior Work\nPrior work have shown that the paradox is one-sided, meaning that when training a model on dataset A and evaluating it on dataset B, the model assigns higher likelihoods to B than A only if A is more complex than B Caterini and Loaiza-Ganem (2021). This means that if we train a model on MNIST digits and evaluate it on FMNIST digits, the model assigns higher likelihoods to MNIST.\nWe argue that LID here can be thought of as a measure of complexity! In fact, we have a new paper dedicated to this topic (Kamkari, Ross, Hosseinzadeh, et al. 2024). When the likelihood paradox happens, while likelihood cannot reliably distinguish between in-distribution and OOD data, LID can.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#why-does-the-paradox-happen-in-the-first-place",
    "href": "sections/ood.html#why-does-the-paradox-happen-in-the-first-place",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "4 Why Does the Paradox Happen in the First Place?",
    "text": "4 Why Does the Paradox Happen in the First Place?\nOur work explains why the model never generates OOD data, despite assigning high likelihoods to it. However, the question of why this paradox occurs in different generative models has been explored in the literature. For example, (Kirichenko, Izmailov, and Wilson 2020) and (Schirrmeister et al. 2020) argue that the inductive biases of the networks used for generative modeling are the culprit. These networks tend to over-fixate on high-frequency patterns in the images, leading them to assign high likelihoods to all natural images, regardless of whether they are in-distribution or OOD. In fact, due to simplicity priors discussed in (Caterini and Loaiza-Ganem 2021), the model may assign higher likelihoods to OOD data than to in-distribution data.\nThus, we see our explanation as complementary to these works. While they explain why the model assigns high likelihoods to OOD data, we provide an explanation for why the model never generates OOD data. We use this observation to design a new OOD detection algorithm.",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/ood.html#how-to-use-our-method",
    "href": "sections/ood.html#how-to-use-our-method",
    "title": "Out-of-Distribution Detection and the Likelihood Paradox",
    "section": "5 How to Use Our Method?",
    "text": "5 How to Use Our Method?\nWe have provided a hands-on guide to get started with our method here. Please cite our repository and paper using the following:\n@misc{dgm_geometry_github,\n  author = {Hamidreza Kamkari, Brendan Leigh Ross, Jesse C. Cresswell, Gabriel Loaiza-Ganem},\n  title = {DGM Geometry},\n  year = {2024},\n  howpublished = {\\url{https://github.com/blross/dgm-geometry}},\n  note = {GitHub repository},\n}\n\n@article{kamkari2024oodlid,\n  title={A Geometric Explanation of the Likelihood OOD Detection Paradox},\n  author={Kamkari, Hamidreza and Ross, Brendan Leigh and Cresswell, Jesse C and Caterini, Anthony L and Krishnan, Rahul G and Loaiza-Ganem, Gabriel},\n  journal={arXiv preprint arXiv:2403.18910},\n  year={2024}\n}",
    "crumbs": [
      "Home",
      "Out-of-distribution detection"
    ]
  },
  {
    "objectID": "sections/lid/manifold_datasets.html",
    "href": "sections/lid/manifold_datasets.html",
    "title": "Manifold Datasets",
    "section": "",
    "text": "This notebook contains an overview of the different types of manifold datasets and distributions that are available for benchmarking different methods. All of these datasets have a corresponding torch distribution where you can define and sample from.\nCode\nfrom notebook_setup import device\n\nimport torch\n\ndevice = torch.device(\"cpu\")\nimport matplotlib.pyplot as plt\n\n%load_ext autoreload",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Manifold Datasets"
    ]
  },
  {
    "objectID": "sections/lid/manifold_datasets.html#lollipop",
    "href": "sections/lid/manifold_datasets.html#lollipop",
    "title": "Manifold Datasets",
    "section": "1 Lollipop",
    "text": "1 Lollipop\nThis is a dataset that contains three submanifolds: (1) a candy which is a 2D circle, (2) a stick which is a 1D line, and (3) an isolated point. You can tune the center of the candy and the length of the stick if you want.\n\n\nCode\n%autoreload 2\n\nfrom data.distributions import Lollipop\nfrom visualization.pretty import ColorTheme\n\nlollipop_distribution = Lollipop(\n    center_loc=(4, 5),\n    radius= 2.0,\n    stick_end_loc=(10, 0),\n    dot_loc = (-1.0, 0.0),\n    candy_ratio=1,\n    stick_ratio=1,\n    dot_ratio=1,\n)\nfig, ax = plt.subplots(1, 1, figsize=(4, 3))\n\nx = lollipop_distribution.sample(10000)\nax.scatter(x[:, 0], x[:, 1], color=ColorTheme.GOLD.value)\nplt.tight_layout(pad=1.0)\nplt.show()",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Manifold Datasets"
    ]
  },
  {
    "objectID": "sections/lid/manifold_datasets.html#swiss-roll",
    "href": "sections/lid/manifold_datasets.html#swiss-roll",
    "title": "Manifold Datasets",
    "section": "2 Swiss Roll",
    "text": "2 Swiss Roll\nThis is a tasty 2D swiss roll embedded in 3D space!\n\n\nCode\n%autoreload 2\nfrom data.distributions import SwissRoll\nfrom visualization.pretty import ColorTheme\ndistribution = SwissRoll()\n\ncream = distribution.sample(10000) # sample the cream!\nchocolate = distribution.sample(10000) # sample the chocolate!\nplt.figure(figsize=(8, 6))\nax = plt.axes(projection='3d')\n\n# plot them using a map c which is set to colors\nax.scatter(cream[:, 0], cream[:, 1], cream[:, 2], color=ColorTheme.CREAM.value , alpha=0.5)\nax.scatter(chocolate[:, 0], chocolate[:, 1], chocolate[:, 2], color=ColorTheme.CHOCOLATE.value, alpha=0.4)\nplt.title(\"Tasty Swiss Roll!\")\nplt.show()",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Manifold Datasets"
    ]
  },
  {
    "objectID": "sections/lid/manifold_datasets.html#affine-manifolds",
    "href": "sections/lid/manifold_datasets.html#affine-manifolds",
    "title": "Manifold Datasets",
    "section": "3 Affine Manifolds",
    "text": "3 Affine Manifolds\nYou can also instantiate a distribution which is a mixture of different dimensional affine manifolds. For example, the following code instantiates a distribution with 3 affine manifolds: a 3D cube, a 1D line, and an isolated point.\n\n\nCode\n%autoreload 2\nfrom data.distributions import AffineManifoldMixture\nfrom visualization.pretty import ColorTheme\n\ndistribution = AffineManifoldMixture(\n    manifold_dims=[1, 2, 3],\n    ambient_dim=3,\n    affine_projection_type=\"random-rotation\",\n    mixture_probs=[0.5, 0.25, 0.25], # if you don't set it it will assign equal probabilities to each component\n    seed=111,\n    distance_between_modes=7,\n)\n\nret = distribution.sample(10000, return_dict=True)\ndata = ret[\"samples\"]\nidx = ret[\"idx\"]\n\nplt.figure(figsize=(8, 6))\nax = plt.axes(projection='3d')\n\nax.scatter(data[idx==0, 0], data[idx==0, 1], data[idx==0, 2], color=ColorTheme.GOLD.value, alpha=0.5, label=\"1d manifold\")\nax.scatter(data[idx==1, 0], data[idx==1, 1], data[idx==1, 2], color=ColorTheme.RED_FIRST.value, alpha=0.5, label=\"2d manifold\")\nax.scatter(data[idx==2, 0], data[idx==2, 1], data[idx==2, 2], color=ColorTheme.BLUE_FIRST.value, alpha=0.5, label=\"3d manifold\")\nplt.title(\"Affine manifold mixture\")\nplt.legend()\nplt.show()\n    \n\n\n\n\n\n\n\n\n\nThe way this distribution works is that for each manifold of intrinsic dimensionality ‘d’, the distribution samples a point from a d-dimensional standard normal/uniform/laplace distribution and then applies an affine transformation to it to embedd it in a higher dimensional space. There are four different types of projections:\n\nOrthogonal: The affine transformation is a random orthogonal matrix.\nRandom: The affine transformation is a random matrix.\nRepeat: Repeat the elements until the desired dimensionality is reached. For example, to embed [1, 2, 3] in a 5D space, the result would be [1, 2, 3, 1, 2].\nZero-pad: The affine transformation pads the vector with zeros until the desired dimensionality is reached.\n\nIt isn’t recommended to use the random projection because a random linear transform might squeeze or stretch the data in a way that might impact the empirical LID of the manifold. In other words, if the manifold is squeezed dramatically in one direction, the LID might become lower.",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Manifold Datasets"
    ]
  },
  {
    "objectID": "sections/lid/manifold_datasets.html#unlocking-generic-manifolds-using-diffeomorphic-transformations",
    "href": "sections/lid/manifold_datasets.html#unlocking-generic-manifolds-using-diffeomorphic-transformations",
    "title": "Manifold Datasets",
    "section": "4 Unlocking generic manifolds using diffeomorphic transformations",
    "text": "4 Unlocking generic manifolds using diffeomorphic transformations\nAlthough affine manifolds are good, they are not flexible and cannot represent the distribution of complex dataset such as images. To create a harder manifold benchmark, pass each affine manifold through a diffeomorphism to obtain a more complex manifold with the same intrinsic dimensionality. The class ManifoldMixtures allows you to define a distribution with a mixture of different manifolds by first performing an affine projection and then applying an arbitrary diffeomorphism on each of the mixture components.\nThese diffeomporphisms can be obtained from a normalizing flow, allowing full flexibility defining the distribution. As an example, run the following code which instantiates a mixture of 4 manifolds: two 1D and two 2D manifolds where one of each is also passed through a neural spline flow to become non-linear:\n\n\nCode\n%autoreload 2\nfrom data.distributions import ManifoldMixture\nfrom models.flows.diffeomorphisms import RQNSF\nimport functools\nfrom visualization.pretty import ColorTheme\n        \nrq_nsf_diffeo = functools.partial(\n    RQNSF, \n    n_transforms=32, \n    n_hidden=32, \n    n_blocks=3, \n)\n\n\ndistribution = ManifoldMixture(\n    manifold_dims=[1, 2, 1, 2],\n    ambient_dim=2,\n    diffeomorphism_instantiator=[rq_nsf_diffeo, rq_nsf_diffeo, None, None], # the first two are passed through diffeomorphisms\n    affine_projection_type=\"zero-pad\",\n    distance_between_modes=6,\n    sample_distr=\"uniform\",\n    seed=666,\n)\n\n\nret = distribution.sample((10000, ), chunk_size=128, return_dict=True)\ndata = ret[\"samples\"]\nlid = ret[\"lid\"]\nidx = ret[\"idx\"]\n\nplt.figure(figsize=(8, 6))\nplt.scatter(data[idx == 0, 0], data[idx==0, 1], color=ColorTheme.GOLD.value, alpha=0.5, label=\"1d non-linear manifold\")\nplt.scatter(data[idx == 1, 0], data[idx==1, 1], color=ColorTheme.RED_FIRST.value, alpha=0.5, label=\"2d non-linear manifold\")\nplt.scatter(data[idx == 2, 0], data[idx==2, 1], color=ColorTheme.BLUE_FIRST.value, alpha=0.5, label=\"1d affine manifold\")\nplt.scatter(data[idx == 3, 0], data[idx==3, 1], color=ColorTheme.RED_SECOND.value, alpha=0.5, label=\"2d affine manifold\")\nplt.legend()\nplt.title(\"Manifold mixture with diffeomorphisms\")\nplt.show()\n\n\n\n\n\n\n\n\n\nGenerally, increasing the number of transforms in the RQ-NSF would increase the complexity.\nNOTE: Beware that while using complex diffeomorphisms does not change the intrinsic dimensionality of the manifold in theory, in practice, it might squeeze or stretch the manifold such that the empirical dimensionality does not match the true dimensionality. In this scenario, the distribution can be unfair! Thus, we recommend not going above a number of transforms that is not necessary for the task at hand.\n\n4.1 Additive and Affine flows\nYou can also use additive or affine flows which are less expressive and can make the benchmark relatively easier. Run the following two blocks to visualize:\n\n\nCode\nfrom models.flows.diffeomorphisms import AffineFlow\n\naffine_diffeo = functools.partial(\n    AffineFlow,\n    n_transforms=10,\n    n_hidden=32,\n    n_blocks=3,\n)\n\n\ndistribution = ManifoldMixture(\n    manifold_dims=[1, 2, 1, 2],\n    ambient_dim=2,\n    diffeomorphism_instantiator=[\n        affine_diffeo,\n        affine_diffeo,\n        None,\n        None,\n    ],  # the first two are passed through diffeomorphisms\n    affine_projection_type=\"zero-pad\",\n    distance_between_modes=6,\n    sample_distr=\"uniform\",\n    seed=666,\n)\n\n\nret = distribution.sample((10000,), chunk_size=128, return_dict=True)\ndata = ret[\"samples\"]\nlid = ret[\"lid\"]\nidx = ret[\"idx\"]\nplt.figure(figsize=(8, 6))\n\nplt.scatter(\n    data[idx == 0, 0],\n    data[idx == 0, 1],\n    color=ColorTheme.GOLD.value,\n    alpha=0.5,\n    label=\"1d non-linear manifold\",\n)\nplt.scatter(\n    data[idx == 1, 0],\n    data[idx == 1, 1],\n    color=ColorTheme.RED_FIRST.value,\n    alpha=0.5,\n    label=\"2d non-linear manifold\",\n)\nplt.scatter(\n    data[idx == 2, 0],\n    data[idx == 2, 1],\n    color=ColorTheme.BLUE_FIRST.value,\n    alpha=0.5,\n    label=\"1d affine manifold\",\n)\nplt.scatter(\n    data[idx == 3, 0],\n    data[idx == 3, 1],\n    color=ColorTheme.RED_SECOND.value,\n    alpha=0.5,\n    label=\"2d affine manifold\",\n)\nplt.legend()\nplt.title(\"Manifold mixture with diffeomorphisms\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom models.flows.diffeomorphisms import AdditiveFlow\n\naffine_diffeo = functools.partial(\n    AdditiveFlow,\n    n_transforms=32,\n    n_hidden=32,\n    n_blocks=3,\n)\n\n\ndistribution = ManifoldMixture(\n    manifold_dims=[1, 2, 1, 2],\n    ambient_dim=2,\n    diffeomorphism_instantiator=[\n        affine_diffeo,\n        affine_diffeo,\n        None,\n        None,\n    ],  # the first two are passed through diffeomorphisms\n    affine_projection_type=\"zero-pad\",\n    distance_between_modes=6,\n    sample_distr=\"uniform\",\n    seed=666,\n)\n\n\nret = distribution.sample((10000,), chunk_size=128, return_dict=True)\ndata = ret[\"samples\"]\nlid = ret[\"lid\"]\nidx = ret[\"idx\"]\n\nplt.scatter(\n    data[idx == 0, 0],\n    data[idx == 0, 1],\n    color=ColorTheme.GOLD.value,\n    alpha=0.5,\n    label=\"1d non-linear manifold\",\n)\nplt.scatter(\n    data[idx == 1, 0],\n    data[idx == 1, 1],\n    color=ColorTheme.RED_FIRST.value,\n    alpha=0.5,\n    label=\"2d non-linear manifold\",\n)\nplt.scatter(\n    data[idx == 2, 0],\n    data[idx == 2, 1],\n    color=ColorTheme.BLUE_FIRST.value,\n    alpha=0.5,\n    label=\"1d affine manifold\",\n)\nplt.scatter(\n    data[idx == 3, 0],\n    data[idx == 3, 1],\n    color=ColorTheme.RED_SECOND.value,\n    alpha=0.5,\n    label=\"2d affine manifold\",\n)\nplt.legend()\nplt.title(\"Manifold mixture with diffeomorphisms\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n4.2 Controlled manifolds using prespecified diffeomorphisms\nHere we use controlled diffeomorphisms to rotate the data with a specific degree that we want:\n\n\nCode\n%autoreload 2\nfrom data.distributions import ManifoldMixture\nfrom models.flows.diffeomorphisms import Rotation\nimport functools\nimport math\n\nrot110 = functools.partial(Rotation, angles=[110. / 180. * math.pi])\nrot45 = functools.partial(Rotation, angles=[45. / 180. * math.pi])\n\ndistribution = ManifoldMixture(\n    manifold_dims=[2, 1, 1],\n    ambient_dim=2,\n    diffeomorphism_instantiator=[None, rot110, rot45],\n    affine_projection_type=\"zero-pad\",\n    distance_between_modes=5,\n    sample_distr=\"uniform\",\n    seed=53,\n)\n\n\nret = distribution.sample((10000, 2), return_dict=True)\ndata = ret[\"samples\"]\nlid = ret[\"lid\"]\nidx = ret[\"idx\"]\ncolors = [ColorTheme.GOLD.value, ColorTheme.RED_FIRST.value, ColorTheme.BLUE_FIRST.value]\nfor i in range(3):\n    plt.scatter(data[idx == i, 0], data[idx == i, 1], color=colors[i], label=f\"Mode {i} with lid = {lid[idx==i][0]}\", alpha=0.5)\nplt.legend()\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Manifold Datasets"
    ]
  },
  {
    "objectID": "sections/lid/manifold_datasets.html#squiggly-manifolds",
    "href": "sections/lid/manifold_datasets.html#squiggly-manifolds",
    "title": "Manifold Datasets",
    "section": "5 Squiggly Manifolds",
    "text": "5 Squiggly Manifolds\nSquiggly manifolds are a class of good high dimensional benchmarks because they are 1. Highly non-linear 2. Have good condition numbers by design 3. We can control how much non-linear they are using a frequency hyperparameter.\nThe idea starts off by obvserving that the “squiggly” function f(x) = x + (1 - \\epsilon) \\frac{sin(\\omega x)}{\\omega} does not perturb that much as we perturb x, thus it has a bounded condition number. Moreover, we can obtain a complex diffeomorphism by chaining elementwise f(x) functions and random rotations. Chaining them would still ensure that the condition numbers are well-behaved but makes them increasingly more non-linear.\nThis would give us a good baseline to compare LID estimators with. We know that ESS estmators fail when we increase the frequency term \\omega.\n\n\nCode\n%autoreload 2\nfrom data.distributions import SquigglyManifoldMixture\nimport functools\nfrom visualization.pretty import ColorTheme\n\nfig, axs = plt.subplots(1, 5, figsize=(15, 3))\n\nfor ii, control in enumerate([0.4, 1., 10., 20., 100.]):\n    distribution = SquigglyManifoldMixture(\n        manifold_dims=[2, 1, 1],\n        ambient_dim=2,\n        distance_between_modes=5,\n        sample_distr=\"uniform\",\n        device=device,\n        seed=53,\n        frequency=control,\n    )\n\n\n    ret = distribution.sample((10000, 2), chunk_size=10000, return_dict=True)\n    data = ret[\"samples\"]\n    lid = ret[\"lid\"]\n    idx = ret[\"idx\"]\n    colors = [ColorTheme.GOLD.value, ColorTheme.RED_FIRST.value, ColorTheme.BLUE_FIRST.value]\n    for i in range(3):\n        axs[ii].scatter(data[idx == i, 0], data[idx == i, 1], color=colors[i], label=f\"Mode {i} with lid = {lid[idx==i][0]}\", alpha=0.5)\n    axs[ii].legend()\n    axs[ii].set_title(f\"Freq = {control}\")\nplt.tight_layout(pad=1.0)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nNote that at frequency of 100, the frequency is so high that is not visible anymore when we plot the manifold.",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Manifold Datasets"
    ]
  },
  {
    "objectID": "sections/lid/manifold_datasets.html#high-dimensional-gaussian-soap-bubbles",
    "href": "sections/lid/manifold_datasets.html#high-dimensional-gaussian-soap-bubbles",
    "title": "Manifold Datasets",
    "section": "6 High dimensional Gaussian soap bubbles",
    "text": "6 High dimensional Gaussian soap bubbles\nThe following is an example of a mixture of Gaussians with dimensions 1, 10, 200, and 400 all embedded in an 800 dimensional space. The following visualizes a UMAP representation of it.\n\n\nCode\nfrom data.distributions import ManifoldMixture\nfrom visualization.pretty import ColorTheme\nfrom visualization import visualize_umap_clusters\n\nmanifold_dims = [1, 10, 200, 400]\ndistribution = ManifoldMixture(\n    manifold_dims=manifold_dims,\n    ambient_dim=800,\n    distance_between_modes=50,\n    sample_distr=\"normal\",\n    seed=666,\n)\n\nsamples_dict = distribution.sample(5000, return_dict=True)\ndata = samples_dict[\"samples\"]\nlid = samples_dict[\"lid\"]\nidx = samples_dict[\"idx\"]\n\nclusters = [\n    data[idx == 0],\n    data[idx == 1],\n    data[idx == 2],\n    data[idx == 3],\n]\ncolors = [\n    ColorTheme.GOLD.value,\n    ColorTheme.RED_FIRST.value,\n    ColorTheme.BLUE_FIRST.value,\n    ColorTheme.PIRATE_BLACK.value,\n]\n\nlabels = [f\"{i}d manifold\" for i in manifold_dims]\n\nvisualize_umap_clusters(\n    data=clusters,\n    labels=labels,\n    colors=colors,\n    title=\"High Dimensional Gaussian Mixture (UMAP embedding)\",\n    return_img=False,\n)\n\n\n\n\n\n\n\n\n\nNOTE: For some reason I can’t see the soap bubble on the UMAP embedding here!\nThe following plot shows the norm of the values that are sampled divided by 800. As you can see, for higher dimensional manifolds this norm is more concentrated around 28 which is the radius of the soap-bubble.\n\n\nCode\nimport numpy as np\n\nfor i, data in enumerate(clusters):\n    standardized = (data - data.mean(0)) / data.std(0)\n    norms = np.linalg.norm(standardized, axis=1)\n    # plot a histogram of norms\n    plt.hist(norms, bins=100, alpha=0.5, color=colors[i], label=labels[i], density=True)\nplt.legend()\nplt.xlabel(\"$\\\\Vert x \\\\Vert_2$\")\nplt.ylabel(\"Density\")\nplt.plot()",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Manifold Datasets"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html",
    "href": "sections/lid/lid_guide.html",
    "title": "Using our LID Estimators",
    "section": "",
    "text": "This Notebook guides you through the process of using our LID estimators. We deal with two different types of LID estiamtors: (1) ones that require training or fitting a deep generative model (or can alternatively use a pre-trained one), and (2) traditional LID estiamtors that are “model-free” and do not require training. Let us go over them one by one, but before we do, make sure to run the following cell to initialize the notebook first and take a look at the manifold dataset notebook that contains our manifold datasets where we have access to the underlying manifold with the ground truth LID.\nCode\nfrom notebook_setup import device\n\nimport torch\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nimport matplotlib.pyplot as plt\n\n%load_ext autoreload",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#section",
    "href": "sections/lid/lid_guide.html#section",
    "title": "Using our LID Estimators",
    "section": "4 ",
    "text": "4 \n\n\nCode\n%autoreload 2\nfrom lid.diffusions import CFDM_LID\nimport numpy as np\nfrom tqdm import tqdm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n\n# instantiate the lid_estimator\nlid_estimator = CFDM_LID(\n    data=dset.x,\n    ambient_dim=2,\n    device=device,\n    beta_min= 0.1,\n    beta_max=20,\n    t_max=1.0,\n)\ndata=dset.x\nmode=\"with_preprocessing\"\nt_values=np.linspace(1e-6, 1, 16)\n\nfig, axes = plt.subplots(4, 4, figsize=(15, 12))\n# fig, axes = plt.subplots(1, 2, figsize=(16, 16))\nassert len(t_values) == len(axes.flatten())\nif mode == \"with_preprocessing\":\n    artifact = lid_estimator.preprocess(data)\nfor ax, t in tqdm(\n    zip(axes.flatten(), t_values),\n    desc=\"computing scatterplots\",\n    total=len(t_values),\n):  # Generate 1k points and plot them\n\n    all_lid = lid_estimator.estimate_lid(\n        data, t=t,\n    ).cpu()\n\n    # clip LID values\n    all_lid = np.clip(all_lid, 0, lid_estimator.ambient_dim)\n\n    s = ax.scatter(*data.cpu().T, c=all_lid, cmap=\"plasma\", vmin=0, vmax=2)\n\n    ax.set_title(f\"t={round(t, 3)}\")\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    cbar = fig.colorbar(s, cax=cax, orientation=\"vertical\")\n\n    cbar.set_label(f\"$LID({{{round(t, 2)}}})(\\\\cdot)$\", rotation=90, labelpad=15)\n\nfig.tight_layout(pad=1.0)\nplt.show()",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model",
    "href": "sections/lid/lid_guide.html#model",
    "title": "Using our LID Estimators",
    "section": "1 Model",
    "text": "1 Model",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-gree",
    "href": "sections/lid/lid_guide.html#model-gree",
    "title": "Using our LID Estimators",
    "section": "1 Model-gree",
    "text": "1 Model-gree",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-",
    "href": "sections/lid/lid_guide.html#model-",
    "title": "Using our LID Estimators",
    "section": "1 Model-",
    "text": "1 Model-",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-free",
    "href": "sections/lid/lid_guide.html#model-free",
    "title": "Using our LID Estimators",
    "section": "1 Model-Free",
    "text": "1 Model-Free",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-free-esti",
    "href": "sections/lid/lid_guide.html#model-free-esti",
    "title": "Using our LID Estimators",
    "section": "1 Model-Free Esti",
    "text": "1 Model-Free Esti",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-free-estimators",
    "href": "sections/lid/lid_guide.html#model-free-estimators",
    "title": "Using our LID Estimators",
    "section": "1 Model-Free Estimators",
    "text": "1 Model-Free Estimators\nCommon model-free LID estimators are lPCA, ESS, and MLE. To run model-free estimators, setup your mlflow and run scripts in the following format:\npython scripts/model_free_lid.py dataset=&lt;dataset&gt; lid_method=&lt;lid-method&gt; +experiment=&lt;lid_greyscale | lid_rgb | lid_tabular&gt; subsample_size=&lt;subsample-size&gt;\nExplanation of the arguments:\n\ndataset: The dataset to run the LID estimator on. We have an extensive suite of datasets including lollipop, swiss_roll, cifar10, mnist, to name a few. To see the full list, check out the conf/datasets directory of the codebase.\nlid_method: The LID estimator to run. The available LID estimators include lpca, ess, and mle to name a few.\nexperiment_dir: The directory to save the experiment outputs. The available directories include lid_greyscale, lid_rgb, and lid_tabular for grayscale (28x28), RGB (3x32x32), and tabular datasets, respectively.\nsubsample_size: This performs a subsampling of the dataset to the specified size. This is useful for high-dimensional datasets like CIFAR-10 and MNIST where computing these model-free estimators is intractable for the entire dataset.\n\nExample runs:\n# Lollipop runs:\npython scripts/model_free_lid.py dataset=lollipop lid_method=ess +experiment=lid_tabular subsample_size=10000\npython scripts/model_free_lid.py dataset=lollipop lid_method=lpca +experiment=lid_tabular subsample_size=10000\n# Image Greyscale runs\npython scripts/model_free_lid.py dataset=mnist lid_method=ess +experiment=lid_greyscale subsample_size=4096\npython scripts/model_free_lid.py dataset=fmnist lid_method=lpca +experiment=lid_greyscale subsample_size=4096\n# Image RGB runs\npython scripts/model_free_lid.py dataset=cifar10 lid_method=ess +experiment=lid_rgb subsample_size=4096\n\n1.1 How to interpret the output\nYou should first setup your Mlflow server. Then, you can visualize the outputs for each of these runs. The outputs include the following:\n\nEstimation heatmap: For a holistic view, these scripts will log the UMAP embedding of all the dataset and for each point, they will log the estimated value of LID in the lid_image/heatmap_pred.png file in the artifacts and the true LIDs (if available) will be logged lid_image/heatmap_gt.png file in the artifacts. For example, the images will not have a ground truth files. You can also set the run to not log the heatmap by setting visualize_manifold=null.\nDetailed evaluation: A detailed evaluation of the LID estimator is logged in the results.yaml file in the artifacts. This includes the mean absolute error, mean squared error, concordance index, and many other summary statistics to show how well the LID estimator performed. In cases where the ground truth is not available, you can check the average estimated LID values to see how well the LID estimator performed. You can also see how well the LID estimator performs on each individual submanifold for datasets with multiple known submanifolds (such as lollipop).\nRaw prediction: To perform any additional analysis, the raw predictions are also logged in the prediction.csv file in the artifacts that you can download and analyze.\n\n\n\n1.2 How to tweak the setting\nAs with the rest of the codebase, we use Hydra and one can tweak the configurations above in the command-line. For example, you can set the time hyperparameter of ess to another value that works better:\n# increase the number of neighbours for the estimator\npython scripts/model_free_lid.py dataset=fmnist lid_method=lpca +experiment=lid_greyscale subsample_size=10000 lid_method.preprocess_args.n_neighbours=1000\nFor a more detailed look, you can take a look at the appropriate Hydra configurations in the conf/lid_method/ directory.",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-free-lid-estimators",
    "href": "sections/lid/lid_guide.html#model-free-lid-estimators",
    "title": "Using our LID Estimators",
    "section": "2 Model-free LID Estimators",
    "text": "2 Model-free LID Estimators\nCommon model-free LID estimators are lPCA, ESS, and MLE. We have also implemented our own closed-form diffusion model (CFDM) LID estimator in this repository. To run model-free estimators, setup your mlflow and run scripts in the following format:\npython scripts/model_free_lid.py dataset=&lt;dataset&gt; lid_method=&lt;lid-method&gt; +experiment=&lt;lid_greyscale | lid_rgb | lid_tabular&gt; subsample_size=&lt;subsample-size&gt;\nExplanation of the arguments: 1. dataset: The dataset to run the LID estimator on. The available datasets include lollipop, swiss_roll, cifar10, mnist, to name a few. We essentially cover everything in the conf/datasets directory. 2. lid_method: The LID estimator to run. The available LID estimators include lpca, ess, mle, and cfdm. 3. experiment_dir: The directory to save the experiment outputs. The available directories include lid_greyscale, lid_rgb, and lid_tabular for grayscale, RGB, and tabular datasets, respectively. 4. subsample_size: This performs a subsampling of the dataset to the specified size. This is useful for large datasets like CIFAR-10 and MNIST.\nExample runs:\n# Lollipop runs:\npython scripts/model_free_lid.py dataset=lollipop lid_method=ess +experiment=lid_tabular subsample_size=10000\npython scripts/model_free_lid.py dataset=lollipop lid_method=lpca +experiment=lid_tabular subsample_size=10000\npython scripts/model_free_lid.py dataset=lollipop lid_method=cfdm +experiment=lid_tabular subsample_size=10000\n# Image Greyscale runs\npython scripts/model_free_lid.py dataset=mnist lid_method=ess +experiment=lid_greyscale subsample_size=4096\npython scripts/model_free_lid.py dataset=fmnist lid_method=lpca +experiment=lid_greyscale subsample_size=4096\n# Image RGB runs\npython scripts/model_free_lid.py dataset=cifar10 lid_method=ess +experiment=lid_rgb subsample_size=4096\n\n2.1 How to interpret the output\nYou should first setup your Mlflow server. Then, you can visualize the outputs for each of these runs. The outputs include the following: 1. Estimation heatmap: For a holistic view, these scripts will log the UMAP embedding of all the dataset and for each point, they will log the estimated value of LID in the lid_image/heatmap_pred.png file in the artifacts and the true LIDs (if available) will be logged lid_image/heatmap_gt.png file in the artifacts. For example, the images will not have a ground truth files. You can also set the run to not log the heatmap by setting visualize_manifold=null. 2. Detailed evaluation: A detailed evaluation of the LID estimator is logged in the results.yaml file in the artifacts. This includes the mean absolute error, mean squared error, concordance index, and many other summary statistics to show how well the LID estimator performed. In cases where the ground truth is not available, you can check the average estimated LID values to see how well the LID estimator performed. You can also see how well the LID estimator performs on each individual submanifold for datasets with multiple known submanifolds (such as lollipop). 3. Raw prediction: To perform any additional analysis, the raw predictions are also logged in the prediction.csv file in the artifacts that you can download and analyze.\n\n\n2.2 How to tweak the lid method setting\nThe configurations above are the default settings for each of the LID estimators. However, you can tweak the settings just like you do with Hydra normally. For example, you can set the time hyperparameter of cfdm to another value that works better for the FMNIST dataset:\npython scripts/model_free_lid.py dataset=fmnist lid_method=cfdm +experiment=lid_greyscale subsample_size=10000 lid_method.estimation_args.t=0.43\nFor a more detailed look, you can take a look at the appropriate configurations in the conf/ directory.",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#m",
    "href": "sections/lid/lid_guide.html#m",
    "title": "Using our LID Estimators",
    "section": "2 M",
    "text": "2 M",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-based",
    "href": "sections/lid/lid_guide.html#model-based",
    "title": "Using our LID Estimators",
    "section": "3 Model-based",
    "text": "3 Model-based",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-based-estimator",
    "href": "sections/lid/lid_guide.html#model-based-estimator",
    "title": "Using our LID Estimators",
    "section": "3 Model-based Estimator",
    "text": "3 Model-based Estimator",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-based-estimators",
    "href": "sections/lid/lid_guide.html#model-based-estimators",
    "title": "Using our LID Estimators",
    "section": "3 Model-based Estimators ()",
    "text": "3 Model-based Estimators ()",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-based-estimators-using-scri",
    "href": "sections/lid/lid_guide.html#model-based-estimators-using-scri",
    "title": "Using our LID Estimators",
    "section": "2 Model-based Estimators (using scri)",
    "text": "2 Model-based Estimators (using scri)",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-based-estimators-using-scripts",
    "href": "sections/lid/lid_guide.html#model-based-estimators-using-scripts",
    "title": "Using our LID Estimators",
    "section": "2 Model-based Estimators (using scripts)",
    "text": "2 Model-based Estimators (using scripts)\nSimilar to the scripts we use for model-free estimators, we have scripts for model-based estimators. Since the model-based estimators require training a deep generative model, these estimators have been developed as a lightning callback to monitor the LID during training. In case, you want to use your pre-trained model, you can simply set the checkpoint argument. For example, we have already included checkpoints for FMNIST/MNIST/CIFAR-10/SVHN, and if you run scripts/download_resources.py they should already be downloaded for you. A simple example would be to run the following:\npython scripts/train.py dataset=mnist +experiment=train_flow_greyscale +checkpoint=flow_mnist +callbacks@all_callbacks.monitor_lid=flow_jacobian_threshold_lid\nThis script uses a pre-trained normalizing flow on MNIST images and employs the Jacobian of the flow push-forward for each individual datapoint to estimate LID. Specifically, it examines the singular values of this Jacobian and uses the threshold \\tau to determine the intrinsic dimension, defined as the number of singular values exceeding the threshold. For more information on this estimator, refer to our paper (Kamkari, Ross, Cresswell, et al. 2024).\nAfter running the script, you can check the artifact directory of MLFlow. You will find a folder named MultiMetrics, which contains a metrics=xxx.csv file. This file includes a column with the estimated LID values for each datapoint. Additionally, you can explore the samples sub-directory to see the samples for which LID was evaluated. A list of all the callbacks are available in the conf/callbacks directory where you can invoke other LID estimators as well.\nBefore we dive into the details of each estimator, let’s first cover some of the basic things that all of these callbacks log:\n\nData summary: The callback logs the data summary in the {logging_folder_name}/manifold_info.csv file in the artifacts directory. This will include all the subsampled datapoints information. If for example, these are from synthetic data where the manifold structure is known, then the columns lid and submanifold will contain the true LID values and the submanifold labels respectively. If not, then these columns will be filled by -1 and 0 respectively; this for example happens with image datasets.\nSeeing samples: All the samples will be logged in {logging_folder_name}/samples/ directory. It will be either a .csv file if the data is tabular and a set of .png and .npy files if the data is an image. In addition to that, each sample has a transformed and an untransformed version. This is because the DGM also has a set of post-hoc transformations that are applied after the DGM generates the samples.\nEvaluating: In all of the monitoring callbacks where a csv file is stored that contains information about all the datapoints, the index of the data (the row it resides in) is consistent with the row in the {logging_folder_name}/manifold_info.csv. Thus, you can join tables and evaluate the performance of LID estimators on a per-sample basis if you want to.\n\nNow let’s dive into each individual estimator:\n\n2.1 Flow Estimators: Using the Jacobian of the Flow Push-Forward\nThis estimator is tailored towards normalizing flows where the mapping from the latent space to the data space is easy to acces and differentiate. All of them work by computing the Jacobian of the flow push-forward for each individual datapoint and estimating the LID based on this Jacobian. Both of them use some sort of scale parameter \\tau to determine the intrinsic dimensionality of the manifold. After running the following scripts, you should be able to reproduce the following curves, indicating the estimated LID for each individual datapoint as a function of \\log \\tau.\n\n\nCode\n%autoreload 2\nimport dotenv\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport re\nfrom visualization.pretty import ColorTheme\nfrom visualization.trend import plot_trends\n# load the environment variables\ndotenv.load_dotenv(override=True)\nimport os\n\ndef visualize_lid_curve(\n    ax, \n    artifact_dir: str, \n    title: str, \n    method_name: str,\n    label: str,\n    alpha=0.01, \n    x_label=\"Sweeping argument\", \n    y_label=\"LID\"\n):\n    # find the directory {artifact_dir}/likelihood_generated/metrics=xxx.csv`\n    lid_curve_dir = os.path.join(artifact_dir, method_name, \"trends\")\n    trend_files = [f for f in os.listdir(lid_curve_dir) if re.match(r'trend_epoch=\\d+\\.csv', f)][-1]\n    trend_in = pd.read_csv(os.path.join(lid_curve_dir, trend_files), index_col=0).values\n\n    sweeping_args_file = [f for f in os.listdir(lid_curve_dir) if f.startswith(\"sweeping_range\")][-1]\n    sweeping_args_df = pd.read_csv(os.path.join(lid_curve_dir, sweeping_args_file), index_col=0)\n    \n    sweeping_arg = sweeping_args_df.columns[0]\n    sweeping_values = sweeping_args_df[sweeping_arg].values\n\n    for i in range(trend_in.shape[0]):\n        ax.plot(sweeping_values, trend_in[i], color=ColorTheme.BLUE_FIRST.value, alpha=alpha)\n    ax.plot([], [], color=ColorTheme.BLUE_SECOND.value, label=label)\n    ax.set_title(title)\n    ax.legend()\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(y_label)\n\n\nfig, axs = plt.subplots(1, 2, figsize=(8, 3))\n\nvisualize_lid_curve(\n    ax=axs[0],\n    artifact_dir=os.getenv(\"LID_FLOW_JACOBIAN_THRESHOLD_MNIST\"),\n    title=\"LID as a function of the singular value threshold\",\n    method_name=\"JacobianThresholdEstimatorCurve\",\n    alpha=0.08,\n    x_label=\"$\\\\log \\\\tau$\",\n    label=\"MNIST Data\",\n)\nvisualize_lid_curve(\n    ax=axs[1],\n    artifact_dir=os.getenv(\"LID_FLOW_FAST_LIDL_MNIST\"),\n    method_name=\"FastFlowLIDLCurve\",\n    title=\"LID as a function of LIDL scale\",\n    alpha=0.08,\n    x_label=\"$\\\\delta \\\\approx \\\\log \\\\tau$\",\n    label=\"MNIST Data\",\n)\nplt.tight_layout(pad=1.0)\nplt.show()\n\n\n\n\n\n\n\n\n\nFigure 1: Visualizing the LID curve of flow-based estimators, the left plot shows the LID curve of the Jacobian threshold estimator on the MNIST dataset, while the right plot shows the LID curve of the fast LIDL estimator. Both plateau at a certain range of the sweeping argument.\n\n\n\n\n\n\n2.1.1 The Jacobian Threshold Estimator\nThis estimator simply computes the singular values of the Jacobian and uses a threshold for which all the singular values above that correspond to on-manifold directions. This estimator can also entail an LID curve: showing for each individual datapoint, the LID estimate as a function of the threshold, this will give a more holistic view of the manifold locally around each datapoint. To run this LID curve, for example on the MNIST dataset, run the following command:\n# set a smaller subsample size to make the run faster\npython scripts/train.py dataset=mnist +experiment=train_flow_greyscale +checkpoint=flow_mnist +callbacks@all_callbacks.monitor_lid=flow_jacobian_threshold_lid_curve all_callbacks.monitor_lid.subsample_size=128\ndotenv set LID_FLOW_JACOBIAN_THRESHOLD_MNIST \"&lt;artifact-dir&gt;\"\nOr the following for a lollipop dataset:\n# this might take some time because it will also train a model\npython scripts/train.py dataset=lollipop +experiment=train_flow_tabular train.trainer.max_epochs=3   +callbacks@all_callbacks.monitor_lid=flow_jacobian_threshold_lid_curve\ndotenv set LID_FLOW_JACOBIAN_THRESHOLD_LOLLIPOP &lt;artifact-dir&gt;\nThe following piece of code will visualize the LID curve as well as the estimates for a calibrated value of threshold \\tau on the Lollipop dataset.\n\n\nCode\n# load the environment variables\nimport dotenv\nimport numpy as np\ndotenv.load_dotenv(override=True)\nfrom visualization.pretty import ColorTheme\n\ndef visualize_scatterplot(\n    ax, \n    artifact_dir: str, \n    title: str, \n    method_name: str,\n    label: str,\n    alpha=0.01, \n):\n    # find the directory {artifact_dir}/likelihood_generated/metrics=xxx.csv`\n    lid_curve_dir = os.path.join(artifact_dir, method_name, \"trends\")\n    trend_files = [f for f in os.listdir(lid_curve_dir) if re.match(r'trend_epoch=\\d+\\.csv', f)][-1]\n    trend_in = pd.read_csv(os.path.join(lid_curve_dir, trend_files), index_col=0).values\n\n    sweeping_args_file = [f for f in os.listdir(lid_curve_dir) if f.startswith(\"sweeping_range\")][-1]\n    sweeping_args_df = pd.read_csv(os.path.join(lid_curve_dir, sweeping_args_file), index_col=0)\n    \n    sweeping_arg = sweeping_args_df.columns[0]\n    sweeping_values = sweeping_args_df[sweeping_arg].values\n\n    # find the index that has sweeping_values close to -4\n    idx = np.abs(sweeping_values + 4).argmin()\n    \n    points = pd.read_csv(os.path.join(artifact_dir, method_name, \"samples\", \"datapoints.csv\"), index_col=0).values\n\n    lid_values = trend_in[:, idx]\n\n    # createa a scatterplot of points with each point being colored by the LID value\n    ax.scatter(points[:, 0], points[:, 1], c=lid_values, cmap=\"viridis\", alpha=0.5)\n    # also show the colorbar\n    cbar = plt.colorbar(ax.collections[0], ax=ax)\n    cbar.set_label(\"LID\")\n    ax.set_title(title)\n    ax.legend()\n\n\nfig, axs = plt.subplots(1, 2, figsize=(8, 3))\n\nvisualize_lid_curve(\n    ax=axs[0],\n    artifact_dir=os.getenv(\"LID_FLOW_JACOBIAN_THRESHOLD_LOLLIPOP\"),\n    title=\"LID as a function of the threshold\",\n    method_name=\"JacobianThresholdEstimatorCurve\",\n    alpha=0.01,\n    label=\"Lollipop Data\",\n    x_label=\"$\\\\log \\\\tau$\",\n)\naxs[0].axvline(x=-4, color=ColorTheme.PIRATE_GOLD.value, linestyle=\"--\")\nvisualize_scatterplot(\n    ax=axs[1],\n    artifact_dir=os.getenv(\"LID_FLOW_JACOBIAN_THRESHOLD_LOLLIPOP\"),\n    method_name=\"JacobianThresholdEstimatorCurve\",\n    title=\"LID Estiamtes for lollipop\",\n    alpha=0.08,\n    label=\"Lollipop Data\",\n)\nplt.tight_layout(pad=1.0)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2: Visualzing the LID curve and estimates of the flow-based method for the lollipop dataset. The left plot shows the LID curve of the Jacobian threshold estimator, where you can see different clusters of data. At a given threshold \\tau=-4 it seems that a cluster of points estimate LID=2, a cluster LID=1, and a cluster LID=0. The right plot shows the LID estimates of these points on a scatterplot, indeed, showing that the ones on the stick are estimated as 1, the ones on the candy as 2, and the ones on the isolated point are estimated as 0.\n\n\n\n\n\n\n\n2.1.2 Fast Flow LIDL (Advanced)\nThis is a continuous proxy for the Jacobian threshold approach. It is based on Tempczyk et al. (LIDL) and Kamkari et al., which is a previous version of (Kamkari, Ross, Cresswell, et al. 2024) and the LID is approximated by a continuous proxy of the Jacobian thresholding. While the thresholding approach is much simpler and promising, the fact that this estimator also produces similar results and is both continuous and differentiable makes it worthwhile mentioning here.\nThe basic theory stems from LIDL, where LID can be approximated by how fast the log probability of a datapoint washes out as we add more and more Gaussian noise. We refer the reader to the paper for more details, but will state the main results here formally, defining the convolution between a pre-trained density p_\\theta and a Gaussian with log standard deviation r as \\begin{align}\n\\begin{aligned}\n    \\varrho_\\delta(\\mathbf{x})& := [p_\\theta(\\cdot )* \\mathcal{N}(\\ \\cdot \\ ; \\mathbf{0}, e^{2\\delta}\\mathbf{I}_d)](\\mathbf{x}) \\\\\n    &=\\int p_\\theta(\\mathbf{x}{-}\\mathbf{x}')\\mathcal{N}(\\mathbf{x}'; \\mathbf{0}, e^{2\\delta}\\mathbf{I}_d) \\mathbf{d} \\mathbf{x}',\n\\end{aligned}\n\\end{align} (Tempczyk et al. 2022) showed that under mild regularity conditions, for sufficiently negative \\delta (i.e. small standard deviation), \\begin{equation}\n     \\log \\varrho_{\\delta}(\\mathbf{x}) = \\delta (\\text{LID}_\\theta(\\mathbf{x}) - d) + \\mathcal{O}(1).\n\\end{equation}\n implies that, for sufficiently negative r (corresponding to sufficiently small noise), the rate of change of \\log \\varrho_\\delta(\\mathbf{x}_0) with respect to r can be used to estimate LID, since \\frac{\\partial}{\\partial r} \\log \\varrho_\\delta(\\mathbf{x}_0) \\approx \\text{LID}_\\theta(\\mathbf{x}_0) - d.\nIn LIDL, estimating \\varrho_\\delta(\\mathbf{x}_0) requires training a separate density model for each r value of interest. This is computationally expensive. Instead, we propose a way to leverage the properties of NFs to approximate \\varrho_\\delta(\\mathbf{x}_0). We assume that our normalizing flow has trained a push-forward f_\\theta: \\mathcal{Z} \\to \\mathcal{X} from a latent space \\mathcal{Z} to the data space \\mathcal{X}. Given a reference point \\mathbf{x}_0 and using a first order Taylor approximation of f_\\theta around \\mathbf{z}_0 = f^{-1}_\\theta (\\mathbf{x}_0), we approximate the NF as an affine function f_\\theta(\\mathbf{z}) \\approx \\mathbf{J}_0 (\\mathbf{z} - \\mathbf{z}_0) + \\mathbf{x}_0, where \\mathbf{J}_0 is the Jacobian of f_\\theta evaluated at \\mathbf{z}_0 and is tractable by design. Since p_\\mathcal{Z} is Gaussian and affine transformations of Gaussians remain Gaussian, we can thus approximate p_\\theta(\\mathbf{x}) as \\hat{p}_\\theta(\\mathbf{x}) \\coloneqq \\mathcal{N}(\\mathbf{x}; \\mathbf{x}_0 - \\mathbf{J}_0 \\mathbf{z}_0, \\mathbf{J}_0 \\mathbf{J}_0^\\top). While it might at first appear strange to approximate a function f_\\theta and a density p_\\theta that we can already evaluate, this approximation makes convolutions analytically tractable. By convolving \\hat{p}_\\theta (instead of p_\\theta) with a Gaussian, we can approximate \\varrho_\\delta(\\mathbf{x}_0) from as\n\\begin{align}\n    \\begin{aligned}\n        \\hat{\\varrho}_\\delta(\\mathbf{x}_0) &\\coloneqq \\int \\hat{p}_\\theta(\\mathbf{x}_0 - \\mathbf{x}) \\mathcal{N}(\\mathbf{x}; \\mathbf{0}, e^{2\\delta}\\mathbf{I}_d)\\mathbf{d} \\mathbf{x} \\\\\n        &= \\mathcal{N}(\\mathbf{x}_0; \\mathbf{x}_0 - \\mathbf{J}_0 \\mathbf{z}_0, \\mathbf{J}_0 \\mathbf{J}_0^\\top + e^{2\\delta}\\mathbf{I}_d).\n    \\end{aligned}\n\\end{align}\nFor a detailed analysis of the quality of this approximation, we refer the reader to the paper. However, we can now simply compute the derivative of the log-density computed above to obtain an estimator for LID. Note that to have a shared nomanclature with the other components, we will use \\tau := e^\\delta and \\log \\tau \\approx \\delta whenever we refer to these estimators. There’s an interpretation of e^\\delta acting as a threshold over the singular values of the Jacobian of the flow push-forward, and the estimator is essentially a continuous and differentiable proxy for the Jacobian threshold estimator.\nTo run this estimator, for example on the MNIST dataset, run the following command:\npython scripts/train.py dataset=mnist +experiment=train_flow_greyscale +checkpoint=flow_mnist +callbacks@all_callbacks.monitor_lid=fast_flow_lidl_curve all_callbacks.monitor_lid.subsample_size=128\ndotenv set LID_FLOW_FAST_LIDL_MNIST &lt;artifact-dir&gt;\n\n\n\n2.2 Diffusion Estimators: Using the Score Function\n\n2.2.1 Normal Bundle Estimator\nThis estimator is based on a study by (Stanczuk et al. 2022) where the score function is sampled around the manifold and the LID is estimated based on the normal bundles of the manifold. To run this estimator, for example on the MNIST dataset, run the following command:\n# you can change the frequency to control how often during training you want to monitor LID\npython scripts/train.py dataset=mnist +experiment=train_diffusion_greyscale +checkpoint=diffusion_mnist +callbacks@all_callbacks.monitor_lid=normal_bundle_lid_curve all_callbacks.monitor_lid.subsample_size=128\ndotenv set LID_DIFFUSION_NORMAL_BUNDLE_MNIST &lt;artifact-dir&gt;\n\n\nCode\nimport dotenv\ndotenv.load_dotenv(override=True)\nfig, axs = plt.subplots(1, 1, figsize=(4, 3))\n\nvisualize_lid_curve(\n    ax=axs,\n    artifact_dir=os.getenv(\"LID_DIFFUSION_NORMAL_BUNDLE_MNIST\"),\n    title=\"LID Curve for normal bundle estimator\",\n    method_name=\"NormalBundleEstimatorCurve\",\n    alpha=0.08,\n    x_label=\"$\\\\log \\\\tau$\",\n)\nplt.tight_layout(pad=1.0)\nplt.show()\n\n\n\n\n\n\n\n\n\nThis will also log an LID curve where for each datapoint the LID is evaluated as a function of a threshold \\tau. For more information check out the appropriate section in  that subsantiates how to adapt this method for vairane-preserving diffusion models.\n\n\n\n2.3 Fokker Planck Estimator (FLIPD: Coming soon!)\nWhen posted, you can run our estimator FLIPD (Kamkari, Ross, Hosseinzadeh, et al. 2024) here!\n\n\n2.4 LIDL Estimator\nThis is a method proposed by (Tempczyk et al. 2022). Unlike the other estimators, this one trains an ensemble of density estimation models (typically normalizing flows, but can also be diffusions). Therefore, the LID monitoring for this estimator is a bit different. To run this estimator, for example on the lollipop dataset, run the following command to train an ensemble of 8 models:\npython scripts/train.py dataset=lollipop +experiment=train_lidl_tabular dataset.train.size=4096 dataset.val.size=128 +callbacks@all_callbacks.umap=umap all_callbacks.umap.frequency=1\nNote: Here, the umap callback will actually generate multiple umap embeddings for each of the models in the ensemble.\nAdditional outputs include:\n\nlog likelihood of perturbed data: Every once in a while, the callback will compute the log_prob of all the datapoints for the different models in the ensemble. This is logged in the lid_logs_{estimator_name}/trends/likelihood_trend_epoch={epoch}.png and lid_logs_{estimator_name}/trends/likelihood_trend_epoch={epoch}.csv file where the x-axis are the different noise scales (the logarithm of the standard deviation of the Gaussian) and each trend represents a datapoint with the y-value being the log_prob of the datapoint for the model associated with a specific noise scale.\nRegression: The result of doing a regression on the log_prob of the datapoints is logged in the lid_logs_{estimator_name}/predictions/estimates_{epoch}.csv. As always, the row numbers are consistent with the ones in the manifold_info.csv file. Thus, you can use that to evaluate the performance of LIDL.\n\n\n\n2.5 Stacking the LID Estimator Callbacks\nAs memtioned before, the LID estimators are implemented as callbacks in PyTorch Lightning. This means that you can stack them together and run them simultaneously to get the best comparison. The following is an example of stacking the Jacobian thresholding and Fast Flow LIDL estimator on lollipop:\npython scripts/train.py dataset=lollipop +experiment=train_flow_tabular train.trainer.max_epochs=30 +callbacks@all_callbacks.monitor_lid1=flow_jacobian_threshold_lid_curve all_callbacks.monitor_lid1.subsample_size=128 +callbacks@all_callbacks.monitor_lid2=fast_flow_lidl_curve all_callbacks.monitor_lid2.subsample_size=128\nObviously, we cannot stack LID estimators that use a different underlying model. For example, you cannot stack the Jacobian threshold estimator with the normal bundle estimator or any of the estimtors with the LIDL estimator.",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#mod",
    "href": "sections/lid/lid_guide.html#mod",
    "title": "Using our LID Estimators",
    "section": "3 Mod",
    "text": "3 Mod",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-bna",
    "href": "sections/lid/lid_guide.html#model-bna",
    "title": "Using our LID Estimators",
    "section": "3 Model-bna",
    "text": "3 Model-bna",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-based-estimators-p",
    "href": "sections/lid/lid_guide.html#model-based-estimators-p",
    "title": "Using our LID Estimators",
    "section": "3 Model-based Estimators (P)",
    "text": "3 Model-based Estimators (P)",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-based-estimators-usi",
    "href": "sections/lid/lid_guide.html#model-based-estimators-usi",
    "title": "Using our LID Estimators",
    "section": "3 Model-based Estimators (usi)",
    "text": "3 Model-based Estimators (usi)",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-based-estimators-using-p",
    "href": "sections/lid/lid_guide.html#model-based-estimators-using-p",
    "title": "Using our LID Estimators",
    "section": "3 Model-based Estimators (using p)",
    "text": "3 Model-based Estimators (using p)",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-based-estimators-using-python",
    "href": "sections/lid/lid_guide.html#model-based-estimators-using-python",
    "title": "Using our LID Estimators",
    "section": "3 Model-based Estimators (using python )",
    "text": "3 Model-based Estimators (using python )",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid/lid_guide.html#model-based-estimators-using-python-sdk",
    "href": "sections/lid/lid_guide.html#model-based-estimators-using-python-sdk",
    "title": "Using our LID Estimators",
    "section": "3 Model-based Estimators (using python SDK)",
    "text": "3 Model-based Estimators (using python SDK)\nApart from using scripts, you may also use our LID estimators in your own code. Everything related to LID is stored in lid/ directory. The LID estimators all inherit the LIDEstimator class that has an estiamte_lid function that takes in a batch of datapoints and returns their LID estimates. Here, we include a simple example of using the closed-form diffusion (CFDM) estimator and the fast flow LIDL estimator on the Lollipop dataset.\n\n\nCode\nimport matplotlib.pyplot as plt\nfrom visualization.pretty import ColorTheme\nfrom data.datasets.generated import LIDSyntheticDataset\nfrom data.distributions import Lollipop\n%autoreload 2\n\ndset = LIDSyntheticDataset(\n    size=10000,\n    distribution=Lollipop(),\n    seed=42,\n)\nplt.figure(figsize=(4, 3))\nplt.scatter(*dset.x.T, color=ColorTheme.GOLD.value)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3: The lollipop dataset loaded.\n\n\n\n\n\n\n3.1 A model-free estimator\n\n\nCode\n%autoreload 2\nfrom lid.diffusions import CFDM_LID\nimport numpy as np\nfrom tqdm import tqdm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n\n# instantiate the lid_estimator\nlid_estimator = CFDM_LID(\n    data=dset.x,\n    ambient_dim=2,\n    device=device,\n    beta_min= 0.1,\n    beta_max=20,\n    t_max=1.0,\n)\ndata=dset.x\nt_values=np.linspace(1e-6, 1, 16)\n\nfig, axes = plt.subplots(4, 4, figsize=(15, 12))\n# fig, axes = plt.subplots(1, 2, figsize=(16, 16))\nassert len(t_values) == len(axes.flatten())\nfor ax, t in tqdm(\n    zip(axes.flatten(), t_values),\n    desc=\"computing scatterplots\",\n    total=len(t_values),\n):  # Generate 1k points and plot them\n\n    all_lid = lid_estimator.estimate_lid(\n        data, t=t,\n    ).cpu()\n\n    # clip LID values\n    all_lid = np.clip(all_lid, 0, lid_estimator.ambient_dim)\n\n    s = ax.scatter(*data.cpu().T, c=all_lid, cmap=\"plasma\", vmin=0, vmax=2)\n\n    ax.set_title(f\"t={round(t, 3)}\")\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    cbar = fig.colorbar(s, cax=cax, orientation=\"vertical\")\n\n    cbar.set_label(f\"$LID({{{round(t, 2)}}})(\\\\cdot)$\", rotation=90, labelpad=15)\n\nfig.tight_layout(pad=1.0)\nplt.show()\n    \n\n\n\n\n\nThe LID estimates of the lollipop dataset using the closed form diffusion estimator. The LID estimator has a hyperparameter t that controls the scale of the diffusion. The LID estimates are shown for different values of t and a certain value of t=0.067 seems to be able to separate the lollipop from the stick.\n\n\n\n\n\n\n3.2 A Model-based estimator\nFirst, train a normalizing flow on the lollipop dataset:\n\n\nCode\nfrom models.flows.training import LightningFlow\nfrom models.training import LightweightTrainer\nfrom functools import partial\nfrom torch import optim\nfrom nflows.flows.base import Flow\nfrom nflows.distributions import StandardNormal\nfrom models.flows.diffeomorphisms import RQNSF\n\nflow_model = Flow(\n  transform=RQNSF(\n    dim=2,\n    n_hidden=64, \n    n_blocks=2,\n    tails=\"linear\",\n    num_bins=32,\n    tail_bound=10.0,\n    data_type=\"tabular\",\n    n_transforms=10,\n    include_actnorm=True,\n  ),\n  distribution=StandardNormal(shape=[2]),  \n)\n\ntraining_module = LightningFlow(\n    normalizing_flow=flow_model,\n    optim_partial=partial(optim.Adam, lr=1e-4),\n)\ntrainer = LightweightTrainer(\n    max_epochs=100,\n    device=device,\n)\ntrainer.fit(\n    model=training_module,\n    train_dataloader=torch.utils.data.DataLoader(dset.x.to(device), batch_size=128),\n    ckpt_path='outputs/notebooks/lollipop-flow/',\n)\ngen_samples = training_module.sample(128)\nfrom visualization import visualize_umap_clusters\nfrom visualization.pretty import ColorTheme\n\nvisualize_umap_clusters(\n    data = [gen_samples.cpu().detach().numpy(), dset.x[:1000].cpu().numpy()],\n    labels=[\"generated\", \"real\"],\n    title=\"quality of model\",\n    alpha=0.3,\n    colors=[ColorTheme.GOLD.value, ColorTheme.BLUE_SECOND.value],\n    return_img=False,\n)\n\n# The expected loss: &lt; 0.71\n\n\n\n\n\nTraining a flow model on lollipop and then generating the samples for evaluation. The samples are aligned with the original data, showing that the model has learned the distribution of the lollipop dataset.\n\n\n\n\nNow let’s estimate LID. Again, we have a hyperparametr for scale.\n\n\nCode\n\n\n#| warning: false\n#| fig-cap: \"The LID estimates of the lollipop dataset using the fast LIDL estimator. The LID estimator has a hyperparameter $\\delta$ that controls the scale of the estimator. The LID estimates are shown for different values of $\\delta$ and a certain value of $\\delta=-4.2$ seems to be able to separate the lollipop from the stick.\"\n%autoreload 2\nimport numpy as np\nfrom tqdm import tqdm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom lid.flows import FastFlowLIDL\n\nlid_estimator_flow = FastFlowLIDL(\n    model=flow_model,\n    device=device,\n)\n\ndata=dset.x\ndelta_values=np.linspace(-5, -1, 16)\n\nfig, axes = plt.subplots(4, 4, figsize=(15, 12))\n# fig, axes = plt.subplots(1, 2, figsize=(16, 16))\nassert len(t_values) == len(axes.flatten())\niterator = tqdm(\n    zip(axes.flatten(), delta_values),\n    desc=\"computing scatterplots\",\n    total=len(delta_values),\n)\nfor ax, delta in iterator:  # Generate 1k points and plot them\n\n    all_lid = []\n    for batch_idx, data_batch in enumerate(torch.split(data, 128)):\n        all_lid.append(lid_estimator_flow.estimate_lid(data_batch, delta=delta).cpu())\n        iterator.set_postfix({\"batch\": f\"[{batch_idx}/{len(data)//128}]\"})\n    all_lid = torch.cat(all_lid)\n    # clip LID values\n    all_lid = np.clip(all_lid, 0, lid_estimator.ambient_dim)\n\n    s = ax.scatter(*data.cpu().T, c=all_lid, cmap=\"plasma\", vmin=0, vmax=2)\n\n    ax.set_title(f\"$\\\\delta$={round(delta, 3)}\")\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    cbar = fig.colorbar(s, cax=cax, orientation=\"vertical\")\n\n    cbar.set_label(f\"$LID({{{round(delta, 2)}}})(\\\\cdot)$\", rotation=90, labelpad=15)\n\nfig.tight_layout(pad=1.0)\nplt.show()\n    \n\n\ncomputing scatterplots: 100%|██████████| 16/16 [03:33&lt;00:00, 13.32s/it, batch=[78/78]]",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Using our LID Estimators"
    ]
  },
  {
    "objectID": "sections/lid.html#introducti",
    "href": "sections/lid.html#introducti",
    "title": "Local Intrinsic Dimension Estimation",
    "section": "",
    "text": "High-dimensional data in deep learning applications such as images often resides on low-dimensional submanifolds, which makes learning the properties of the learned manifold by a generative model a relevant problem (Loaiza-Ganem et al. 2024). One of the most important properties of a manifold is its intrinsic dimensionality which can loosely be defined as the number of local factors of variation that describe the data.\nLID reflects the number of local variation factors; more factors indicate greater complexity. Accurate LID estimation benefits various applications, from neural network generalization to detecting out-of-distribution data and adversarial examples. However, existing generative model-based methods for LID estimation are either inaccurate, require multiple models, are computationally expensive, or don’t leverage the best deep generative models, such as diffusion models (DMs).",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension"
    ]
  },
  {
    "objectID": "sections/lid.html#introduction",
    "href": "sections/lid.html#introduction",
    "title": "Local Intrinsic Dimension Estimation",
    "section": "",
    "text": "High-dimensional data in deep learning applications such as images often resides on low-dimensional submanifolds, which makes learning the properties of the learned manifold by a generative model a relevant problem (Loaiza-Ganem et al. 2024). One of the most important properties of a manifold is its intrinsic dimensionality which can loosely be defined as the number of local factors of variation that describe the data.\nLID reflects the number of local variation factors; more factors indicate greater complexity. Accurate LID estimation benefits various applications, from neural network generalization to detecting out-of-distribution data and adversarial examples. However, existing generative model-based methods for LID estimation are either inaccurate, require multiple models, are computationally expensive, or don’t leverage the best deep generative models, such as diffusion models (DMs).",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension"
    ]
  },
  {
    "objectID": "sections/lid/flipd.html",
    "href": "sections/lid/flipd.html",
    "title": "Fokker-Planck LID (FLIPD)",
    "section": "",
    "text": "FLIPD unlocks the capability to estimate LID for ~1M dimensional images of LAION Aesthetics. This figure shows the 4 lowest and highest FLIPD estimates for the dataset, showing a clear seperation of images with respect to their semantic complexity.",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Fokker-Planck LID (FLIPD)"
    ]
  },
  {
    "objectID": "sections/lid/flipd.html#i",
    "href": "sections/lid/flipd.html#i",
    "title": "Fokker-Planck LID (FLIPD)",
    "section": "1 I",
    "text": "1 I\nComing soon …",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Fokker-Planck LID (FLIPD)"
    ]
  },
  {
    "objectID": "sections/lid/flipd.html#introductio",
    "href": "sections/lid/flipd.html#introductio",
    "title": "Fokker-Planck LID (FLIPD)",
    "section": "1 Introductio",
    "text": "1 Introductio\nComing soon …",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Fokker-Planck LID (FLIPD)"
    ]
  },
  {
    "objectID": "sections/lid/flipd.html#introduction",
    "href": "sections/lid/flipd.html#introduction",
    "title": "Fokker-Planck LID (FLIPD)",
    "section": "1 Introduction",
    "text": "1 Introduction\nCheck out our paper at arXiv dsafor more details. The code will be available soon!",
    "crumbs": [
      "Home",
      "Local Intrinsic Dimension",
      "Fokker-Planck LID (FLIPD)"
    ]
  }
]